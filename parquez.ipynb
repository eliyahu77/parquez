{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Parquez pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create the mlrun project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both server & client are aligned (0.6.1).\n"
     ]
    }
   ],
   "source": [
    "!/User/align_mlrun.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project path: /User/parquez\n",
      "Project name: parquez\n"
     ]
    }
   ],
   "source": [
    "from os import path, getenv\n",
    "from mlrun import new_project, mlconf\n",
    "\n",
    "#project_name = '-'.join(filter(None, ['getting-started-iris', getenv('V3IO_USERNAME', None)]))\n",
    "project_name = \"parquez\"\n",
    "project_path = path.abspath('./')\n",
    "project = new_project(project_name, project_path)\n",
    "project.save()\n",
    "print(f'Project path: {project_path}\\nProject name: {project_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONPATH=./\n"
     ]
    }
   ],
   "source": [
    "out = mlconf.artifact_path or path.abspath('./data')\n",
    "# {{run.uid}} will be substituted with the run id, so output will be written to different directoried per run\n",
    "artifact_path = path.join(out, '{{run.uid}}')\n",
    "%env PYTHONPATH=./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set the project functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.kubejob.KubejobRuntime at 0x7f19b8189e50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_name =  'aviaigz/parquez:0.6.1'\n",
    "\n",
    "project.set_function(\"functions/clean_parquez.py\", 'clean', kind='job', image=image_name)\n",
    "project.set_function(\"functions/validate_input.py\", 'validate', kind='job', image=image_name)\n",
    "project.set_function(\"functions/get_table_schema.py\", 'get_schema', kind='job', image=image_name)\n",
    "project.set_function(\"functions/create_parquet_table.py\", 'create_parquet', kind='job', image=image_name)\n",
    "project.set_function(\"functions/create_unified_view.py\", 'create_unified_view', kind='job', image=image_name)\n",
    "project.set_function(\"functions/parquet_add_partition.py\", 'parquet_add_partition', kind='job', image=image_name)\n",
    "project.set_function(\"functions/run_scheduler.py\", 'run_scheduler', kind='job', image=image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deploy kv-to-parquet function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-04-12 12:08:07,136 [info] running build to add mlrun package, set with_mlrun=False to skip if its already in the image\n",
      "> 2021-04-12 12:08:07,137 [info] starting remote build, image: .mlrun/func-parquez-kv-to-parquet-latest\n",
      "E0412 12:08:49.974495       1 aws_credentials.go:77] while getting AWS credentials NoCredentialProviders: no valid providers in chain. Deprecated.\n",
      "\tFor verbose messaging see aws.Config.CredentialsChainVerboseErrors\n",
      "\u001b[36mINFO\u001b[0m[0040] Retrieving image manifest datanode-registry.iguazio-platform.app.dev39.lab.iguazeng.com:80/iguazio/spark-app:3.0_b51_20210308021033 \n",
      "\u001b[36mINFO\u001b[0m[0040] Retrieving image manifest datanode-registry.iguazio-platform.app.dev39.lab.iguazeng.com:80/iguazio/spark-app:3.0_b51_20210308021033 \n",
      "\u001b[36mINFO\u001b[0m[0040] Built cross stage deps: map[]                \n",
      "\u001b[36mINFO\u001b[0m[0040] Retrieving image manifest datanode-registry.iguazio-platform.app.dev39.lab.iguazeng.com:80/iguazio/spark-app:3.0_b51_20210308021033 \n",
      "\u001b[36mINFO\u001b[0m[0040] Retrieving image manifest datanode-registry.iguazio-platform.app.dev39.lab.iguazeng.com:80/iguazio/spark-app:3.0_b51_20210308021033 \n",
      "\u001b[36mINFO\u001b[0m[0040] Executing 0 build triggers                   \n",
      "\u001b[36mINFO\u001b[0m[0040] Unpacking rootfs as cmd RUN pip install \"mlrun[complete]==0.6.1\" requires it. \n",
      "\u001b[36mINFO\u001b[0m[0100] RUN pip install \"mlrun[complete]==0.6.1\"     \n",
      "\u001b[36mINFO\u001b[0m[0100] Taking snapshot of full filesystem...        \n",
      "\u001b[36mINFO\u001b[0m[0109] cmd: /bin/sh                                 \n",
      "\u001b[36mINFO\u001b[0m[0109] args: [-c pip install \"mlrun[complete]==0.6.1\"] \n",
      "\u001b[36mINFO\u001b[0m[0109] util.Lookup returned: &{Uid:1000 Gid:1000 Username:iguazio Name: HomeDir:/igz} \n",
      "\u001b[36mINFO\u001b[0m[0109] performing slow lookup of group ids for iguazio \n",
      "\u001b[36mINFO\u001b[0m[0109] Running: [/bin/sh -c pip install \"mlrun[complete]==0.6.1\"] \n",
      "WARNING: The directory '/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\n",
      "Collecting mlrun[complete]==0.6.1\n",
      "  Downloading mlrun-0.6.1-py3-none-any.whl (392 kB)\n",
      "Collecting requests~=2.22\n",
      "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "Requirement already satisfied: chardet<4.0,>=3.0.2 in /conda/lib/python3.7/site-packages (from mlrun[complete]==0.6.1) (3.0.4)\n",
      "Collecting tabulate<=0.8.3,>=0.8.0\n",
      "  Downloading tabulate-0.8.3.tar.gz (46 kB)\n",
      "Collecting pydantic~=1.5\n",
      "  Downloading pydantic-1.8.1-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
      "Collecting v3iofs~=0.1.5\n",
      "  Downloading v3iofs-0.1.6.tar.gz (16 kB)\n",
      "Collecting orjson<3.4,>=3\n",
      "  Downloading orjson-3.3.1-cp37-cp37m-manylinux2014_x86_64.whl (208 kB)\n",
      "Collecting alembic~=1.4\n",
      "  Downloading alembic-1.5.8-py2.py3-none-any.whl (159 kB)\n",
      "Collecting nuclio-jupyter>=0.8.9\n",
      "  Downloading nuclio_jupyter-0.8.12-py3-none-any.whl (46 kB)\n",
      "Collecting mergedeep~=1.3\n",
      "  Downloading mergedeep-1.3.4-py3-none-any.whl (6.4 kB)\n",
      "Collecting pyyaml~=5.1\n",
      "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "Collecting pyarrow~=1.0\n",
      "  Downloading pyarrow-1.0.1-cp37-cp37m-manylinux2014_x86_64.whl (17.3 MB)\n",
      "Collecting ipython<7.17,>=5.5\n",
      "  Downloading ipython-7.16.1-py3-none-any.whl (785 kB)\n",
      "Collecting humanfriendly~=8.2\n",
      "  Downloading humanfriendly-8.2-py2.py3-none-any.whl (86 kB)\n",
      "Collecting numpy<1.20.0,>=1.16.5\n",
      "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
      "Collecting GitPython~=3.0\n",
      "  Downloading GitPython-3.1.14-py3-none-any.whl (159 kB)\n",
      "Collecting storey~=0.3.4; python_version >= \"3.7\"\n",
      "  Downloading storey-0.3.8-py3-none-any.whl (92 kB)\n",
      "Collecting aiohttp~=3.6\n",
      "  Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
      "Collecting click~=7.0\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting sqlalchemy~=1.3\n",
      "  Downloading SQLAlchemy-1.4.7-cp37-cp37m-manylinux2014_x86_64.whl (1.5 MB)\n",
      "Collecting v3io~=0.5.0\n",
      "  Downloading v3io-0.5.7-py3-none-any.whl (49 kB)\n",
      "Collecting v3io-frames~=0.8.5\n",
      "  Downloading v3io_frames-0.8.14-py3-none-any.whl (35 kB)\n",
      "Collecting kfp~=1.0.1\n",
      "  Downloading kfp-1.0.4.tar.gz (116 kB)\n",
      "Collecting urllib3<1.27,>=1.25.4\n",
      "  Downloading urllib3-1.26.4-py2.py3-none-any.whl (153 kB)\n",
      "Collecting distributed<3,>=2.23\n",
      "  Downloading distributed-2.30.1-py3-none-any.whl (656 kB)\n",
      "Collecting kubernetes~=11.0\n",
      "  Downloading kubernetes-11.0.0-py3-none-any.whl (1.5 MB)\n",
      "Collecting dask~=2.12\n",
      "  Downloading dask-2.30.0-py3-none-any.whl (848 kB)\n",
      "Collecting fastapi~=0.62.0\n",
      "  Downloading fastapi-0.62.0-py3-none-any.whl (49 kB)\n",
      "Collecting cryptography~=3.3.2\n",
      "  Downloading cryptography-3.3.2-cp36-abi3-manylinux2010_x86_64.whl (2.6 MB)\n",
      "Collecting nest-asyncio~=1.0\n",
      "  Downloading nest_asyncio-1.5.1-py3-none-any.whl (5.0 kB)\n",
      "Collecting semver~=2.13\n",
      "  Downloading semver-2.13.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting pandas~=1.2; python_version >= \"3.7\"\n",
      "  Downloading pandas-1.2.3-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\n",
      "Collecting s3fs~=0.5; extra == \"complete\"\n",
      "  Downloading s3fs-0.6.0-py3-none-any.whl (23 kB)\n",
      "Collecting azure-storage-blob<12.7.0,~=12.0; extra == \"complete\"\n",
      "  Downloading azure_storage_blob-12.6.0-py2.py3-none-any.whl (328 kB)\n",
      "Collecting adlfs~=0.6; extra == \"complete\"\n",
      "  Downloading adlfs-0.7.1.tar.gz (37 kB)\n",
      "Collecting botocore<1.19.53,>=1.19.52; extra == \"complete\"\n",
      "  Downloading botocore-1.19.52-py2.py3-none-any.whl (7.2 MB)\n",
      "Collecting boto3<1.16.53,~=1.9; extra == \"complete\"\n",
      "  Downloading boto3-1.16.52-py2.py3-none-any.whl (130 kB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /conda/lib/python3.7/site-packages (from requests~=2.22->mlrun[complete]==0.6.1) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /conda/lib/python3.7/site-packages (from requests~=2.22->mlrun[complete]==0.6.1) (2020.12.5)\n",
      "Collecting typing-extensions>=3.7.4.3\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting fsspec>=0.6.2\n",
      "  Downloading fsspec-0.9.0-py3-none-any.whl (107 kB)\n",
      "Collecting python-dateutil\n",
      "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Collecting python-editor>=0.3\n",
      "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.1.4-py2.py3-none-any.whl (75 kB)\n",
      "Collecting nbconvert>=5.4\n",
      "  Downloading nbconvert-6.0.7-py3-none-any.whl (552 kB)\n",
      "Collecting notebook>=5.2.0\n",
      "  Downloading notebook-6.3.0-py3-none-any.whl (9.5 MB)\n",
      "Collecting pygments\n",
      "  Downloading Pygments-2.8.1-py3-none-any.whl (983 kB)\n",
      "Collecting decorator\n",
      "  Downloading decorator-5.0.6-py3-none-any.whl (8.8 kB)\n",
      "Collecting backcall\n",
      "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting traitlets>=4.2\n",
      "  Downloading traitlets-5.0.5-py3-none-any.whl (100 kB)\n",
      "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
      "  Downloading prompt_toolkit-3.0.18-py3-none-any.whl (367 kB)\n",
      "Collecting jedi>=0.10\n",
      "  Downloading jedi-0.18.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Collecting pickleshare\n",
      "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: setuptools>=18.5 in /conda/lib/python3.7/site-packages (from ipython<7.17,>=5.5->mlrun[complete]==0.6.1) (41.0.0)\n",
      "Collecting pexpect; sys_platform != \"win32\"\n",
      "  Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n",
      "Collecting grpcio~=1.30.0\n",
      "  Downloading grpcio-1.30.0-cp37-cp37m-manylinux2010_x86_64.whl (3.0 MB)\n",
      "Collecting grpcio-tools~=1.30.0\n",
      "  Downloading grpcio_tools-1.30.0-cp37-cp37m-manylinux2010_x86_64.whl (2.5 MB)\n",
      "Collecting attrs>=17.3.0\n",
      "  Downloading attrs-20.3.0-py2.py3-none-any.whl (49 kB)\n",
      "Collecting async-timeout<4.0,>=3.0\n",
      "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142 kB)\n",
      "Collecting importlib-metadata; python_version < \"3.8\"\n",
      "  Downloading importlib_metadata-3.10.0-py3-none-any.whl (14 kB)\n",
      "Collecting greenlet!=0.4.17; python_version >= \"3\"\n",
      "  Downloading greenlet-1.0.0-cp37-cp37m-manylinux2010_x86_64.whl (160 kB)\n",
      "Collecting ujson>=3.0.0\n",
      "  Downloading ujson-4.0.2-cp37-cp37m-manylinux1_x86_64.whl (179 kB)\n",
      "Collecting future>=0.18.2\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "Collecting googleapis-common-protos>=1.5.3\n",
      "  Downloading googleapis_common_protos-1.53.0-py2.py3-none-any.whl (198 kB)\n",
      "Collecting google-cloud-storage>=1.13.0\n",
      "  Downloading google_cloud_storage-1.37.1-py2.py3-none-any.whl (103 kB)\n",
      "Collecting google-auth>=1.6.1\n",
      "  Downloading google_auth-1.28.1-py2.py3-none-any.whl (136 kB)\n",
      "Collecting requests_toolbelt>=0.8.0\n",
      "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
      "Collecting cloudpickle\n",
      "  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
      "Collecting kfp-server-api<2.0.0,>=0.2.5\n",
      "  Downloading kfp-server-api-1.4.1.tar.gz (50 kB)\n",
      "Collecting jsonschema>=3.0.1\n",
      "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
      "Collecting Deprecated\n",
      "  Downloading Deprecated-1.2.12-py2.py3-none-any.whl (9.5 kB)\n",
      "Collecting strip-hints\n",
      "  Downloading strip-hints-0.1.9.tar.gz (30 kB)\n",
      "Collecting sortedcontainers!=2.0.0,!=2.0.1\n",
      "  Downloading sortedcontainers-2.3.0-py2.py3-none-any.whl (29 kB)\n",
      "Collecting tornado>=5; python_version < \"3.8\"\n",
      "  Downloading tornado-6.1-cp37-cp37m-manylinux2010_x86_64.whl (428 kB)\n",
      "Collecting zict>=0.1.3\n",
      "  Downloading zict-2.0.0-py3-none-any.whl (10 kB)\n",
      "Collecting msgpack>=0.6.0\n",
      "  Downloading msgpack-1.0.2-cp37-cp37m-manylinux1_x86_64.whl (273 kB)\n",
      "Collecting psutil>=5.0\n",
      "  Downloading psutil-5.8.0-cp37-cp37m-manylinux2010_x86_64.whl (296 kB)\n",
      "Collecting toolz>=0.8.2\n",
      "  Downloading toolz-0.11.1-py3-none-any.whl (55 kB)\n",
      "Collecting tblib>=1.6.0\n",
      "  Downloading tblib-1.7.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0\n",
      "  Downloading websocket_client-0.58.0-py2.py3-none-any.whl (61 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in /conda/lib/python3.7/site-packages (from kubernetes~=11.0->mlrun[complete]==0.6.1) (1.12.0)\n",
      "Collecting requests-oauthlib\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting starlette==0.13.6\n",
      "  Downloading starlette-0.13.6-py3-none-any.whl (59 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in /conda/lib/python3.7/site-packages (from cryptography~=3.3.2->mlrun[complete]==0.6.1) (1.12.2)\n",
      "Collecting pytz>=2017.3\n",
      "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
      "Collecting aiobotocore>=1.0.1\n",
      "  Downloading aiobotocore-1.3.0.tar.gz (48 kB)\n",
      "Collecting azure-core<2.0.0,>=1.9.0\n",
      "  Downloading azure_core-1.13.0-py2.py3-none-any.whl (133 kB)\n",
      "Collecting msrest>=0.6.10\n",
      "  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\n",
      "Collecting azure-datalake-store<0.1,>=0.0.46\n",
      "  Downloading azure_datalake_store-0.0.52-py2.py3-none-any.whl (61 kB)\n",
      "Collecting azure-identity\n",
      "  Downloading azure_identity-1.5.0-py2.py3-none-any.whl (103 kB)\n",
      "Collecting msrestazure\n",
      "  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n",
      "Collecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting s3transfer<0.4.0,>=0.3.0\n",
      "  Downloading s3transfer-0.3.6-py2.py3-none-any.whl (73 kB)\n",
      "Collecting MarkupSafe>=0.9.2\n",
      "  Downloading MarkupSafe-1.1.1-cp37-cp37m-manylinux2010_x86_64.whl (33 kB)\n",
      "Collecting mistune<2,>=0.8.1\n",
      "  Downloading mistune-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting jupyter-core\n",
      "  Downloading jupyter_core-4.7.1-py3-none-any.whl (82 kB)\n",
      "Collecting defusedxml\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Collecting jinja2>=2.4\n",
      "  Downloading Jinja2-2.11.3-py2.py3-none-any.whl (125 kB)\n",
      "Collecting entrypoints>=0.2.2\n",
      "  Downloading entrypoints-0.3-py2.py3-none-any.whl (11 kB)\n",
      "Collecting nbformat>=4.4\n",
      "  Downloading nbformat-5.1.3-py3-none-any.whl (178 kB)\n",
      "Collecting bleach\n",
      "  Downloading bleach-3.3.0-py2.py3-none-any.whl (283 kB)\n",
      "Collecting jupyterlab-pygments\n",
      "  Downloading jupyterlab_pygments-0.1.2-py2.py3-none-any.whl (4.6 kB)\n",
      "Collecting pandocfilters>=1.4.1\n",
      "  Downloading pandocfilters-1.4.3.tar.gz (16 kB)\n",
      "Collecting nbclient<0.6.0,>=0.5.0\n",
      "  Downloading nbclient-0.5.3-py3-none-any.whl (82 kB)\n",
      "Collecting testpath\n",
      "  Downloading testpath-0.4.4-py2.py3-none-any.whl (163 kB)\n",
      "Collecting terminado>=0.8.3\n",
      "  Downloading terminado-0.9.4-py3-none-any.whl (14 kB)\n",
      "Collecting prometheus-client\n",
      "  Downloading prometheus_client-0.10.1-py2.py3-none-any.whl (55 kB)\n",
      "Collecting ipython-genutils\n",
      "  Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting jupyter-client>=5.3.4\n",
      "  Downloading jupyter_client-6.2.0-py3-none-any.whl (112 kB)\n",
      "Collecting argon2-cffi\n",
      "  Downloading argon2_cffi-20.1.0-cp35-abi3-manylinux1_x86_64.whl (97 kB)\n",
      "Collecting Send2Trash>=1.5.0\n",
      "  Downloading Send2Trash-1.5.0-py3-none-any.whl (12 kB)\n",
      "Collecting ipykernel\n",
      "  Downloading ipykernel-5.5.3-py3-none-any.whl (120 kB)\n",
      "Collecting pyzmq>=17\n",
      "  Downloading pyzmq-22.0.3-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
      "Collecting wcwidth\n",
      "  Downloading wcwidth-0.2.5-py2.py3-none-any.whl (30 kB)\n",
      "Collecting parso<0.9.0,>=0.8.0\n",
      "  Downloading parso-0.8.2-py2.py3-none-any.whl (94 kB)\n",
      "Collecting ptyprocess>=0.5\n",
      "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting smmap<5,>=3.0.1\n",
      "  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting protobuf>=3.5.0.post1\n",
      "  Downloading protobuf-3.15.8-cp37-cp37m-manylinux1_x86_64.whl (1.0 MB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.4.1-py3-none-any.whl (5.2 kB)\n",
      "Collecting google-resumable-media<2.0dev,>=1.2.0\n",
      "  Downloading google_resumable_media-1.2.0-py2.py3-none-any.whl (75 kB)\n",
      "Collecting google-cloud-core<2.0dev,>=1.4.1\n",
      "  Downloading google_cloud_core-1.6.0-py2.py3-none-any.whl (28 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.1-py3-none-any.whl (12 kB)\n",
      "Collecting pyrsistent>=0.14.0\n",
      "  Downloading pyrsistent-0.17.3.tar.gz (106 kB)\n",
      "Collecting wrapt<2,>=1.10\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Requirement already satisfied: wheel in /conda/lib/python3.7/site-packages (from strip-hints->kfp~=1.0.1->mlrun[complete]==0.6.1) (0.33.1)\n",
      "Collecting heapdict\n",
      "  Downloading HeapDict-1.0.1-py3-none-any.whl (3.9 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Requirement already satisfied: pycparser in /conda/lib/python3.7/site-packages (from cffi>=1.12->cryptography~=3.3.2->mlrun[complete]==0.6.1) (2.19)\n",
      "Collecting aioitertools>=0.5.1\n",
      "  Downloading aioitertools-0.7.1-py3-none-any.whl (20 kB)\n",
      "Collecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
      "Collecting adal>=0.4.2\n",
      "  Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\n",
      "Collecting msal<2.0.0,>=1.6.0\n",
      "  Downloading msal-1.11.0-py2.py3-none-any.whl (63 kB)\n",
      "Collecting msal-extensions~=0.3.0\n",
      "  Downloading msal_extensions-0.3.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting webencodings\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Collecting packaging\n",
      "  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
      "Collecting async-generator\n",
      "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\"\n",
      "  Downloading google_crc32c-1.1.2-cp37-cp37m-manylinux2014_x86_64.whl (38 kB)\n",
      "Collecting google-api-core<2.0.0dev,>=1.21.0\n",
      "  Downloading google_api_core-1.26.3-py2.py3-none-any.whl (93 kB)\n",
      "Collecting pyasn1>=0.1.3\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting PyJWT<3,>=1.0.0\n",
      "  Downloading PyJWT-2.0.1-py3-none-any.whl (15 kB)\n",
      "Collecting portalocker~=1.0; platform_system != \"Windows\"\n",
      "  Downloading portalocker-1.7.1-py2.py3-none-any.whl (10 kB)\n",
      "Collecting pyparsing>=2.0.2\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Building wheels for collected packages: tabulate, v3iofs, kfp, adlfs, future, kfp-server-api, strip-hints, aiobotocore, pandocfilters, pyrsistent, wrapt\n",
      "  Building wheel for tabulate (setup.py): started\n",
      "  Building wheel for tabulate (setup.py): finished with status 'done'\n",
      "  Created wheel for tabulate: filename=tabulate-0.8.3-py3-none-any.whl size=23377 sha256=50f03b92703633cc815f37fa1b489b70f8cd76c792ba8ff6ac2454554fcf3ae9\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-s4vr0taf/wheels/b8/a2/a6/812a8a9735b090913e109133c7c20aaca4cf07e8e18837714f\n",
      "  Building wheel for v3iofs (setup.py): started\n",
      "  Building wheel for v3iofs (setup.py): finished with status 'done'\n",
      "  Created wheel for v3iofs: filename=v3iofs-0.1.6-py3-none-any.whl size=12297 sha256=bb19452a5371fcb1e1b1048921448d6f2469fd72cea1670f16071b559e6a8707\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-s4vr0taf/wheels/b0/39/4d/c8f850fd9698770f98e3775d2e42dd33170ff37d4090efb98c\n",
      "  Building wheel for kfp (setup.py): started\n",
      "  Building wheel for kfp (setup.py): finished with status 'done'\n",
      "  Created wheel for kfp: filename=kfp-1.0.4-py3-none-any.whl size=159872 sha256=38845476e4097ecb2eb05b07d37b3ef5c50dc27b5e10acecea21a9f854dbb8df\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-s4vr0taf/wheels/65/1c/be/3d7366d2288bf1587e4fe6cd0c1ebdce5e3bada21b70a29e66\n",
      "  Building wheel for adlfs (setup.py): started\n",
      "  Building wheel for adlfs (setup.py): finished with status 'done'\n",
      "  Created wheel for adlfs: filename=adlfs-0.7.1-py3-none-any.whl size=20148 sha256=c4eae9eaa1e36f37e4847c008d3733ea33b50811e5545851b17f94964dae9eb2\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-s4vr0taf/wheels/25/64/f2/0dfa461661647743ff708d66052bc829d1a4a4fef381e02195\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491056 sha256=9398ac13c7bec0417dd4983c4b568c7011324fcac6c48cea32787e3e4d4b47d1\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-s4vr0taf/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
      "  Building wheel for kfp-server-api (setup.py): started\n",
      "  Building wheel for kfp-server-api (setup.py): finished with status 'done'\n",
      "  Created wheel for kfp-server-api: filename=kfp_server_api-1.4.1-py3-none-any.whl size=92261 sha256=64bbd749d6747fe589df8fb995003b6b52e4925fe78dde464fbe8e46276d5231\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-s4vr0taf/wheels/eb/87/de/e967039ae561f87c24197e6b14bf97df4c3a1208b5f4174426\n",
      "  Building wheel for strip-hints (setup.py): started\n",
      "  Building wheel for strip-hints (setup.py): finished with status 'done'\n",
      "  Created wheel for strip-hints: filename=strip_hints-0.1.9-py2.py3-none-any.whl size=20993 sha256=43a4236301c2d9f18813e1964c75567c0c57972a55e5556478c868fd0f1961a0\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-s4vr0taf/wheels/2d/b8/4e/a3ec111d2db63cec88121bd7c0ab1a123bce3b55dd19dda5c1\n",
      "  Building wheel for aiobotocore (setup.py): started\n",
      "  Building wheel for aiobotocore (setup.py): finished with status 'done'\n",
      "  Created wheel for aiobotocore: filename=aiobotocore-1.3.0-py3-none-any.whl size=45780 sha256=4fcef9e91503831f7b8d4bd7746a0e25766cb64ebad049aa67c8ee8c45207e09\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-s4vr0taf/wheels/46/81/f1/c47c29199f73c49ecca9464f77aa181d267d33c8316d563980\n",
      "  Building wheel for pandocfilters (setup.py): started\n",
      "  Building wheel for pandocfilters (setup.py): finished with status 'done'\n",
      "  Created wheel for pandocfilters: filename=pandocfilters-1.4.3-py3-none-any.whl size=7992 sha256=742ab4895e4d6d1c9710e61902105b490256bff59397dbce5dd2c25b760795a1\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-s4vr0taf/wheels/42/81/34/545dc2fbf0e9137811e901108d37fc04650e81d48f97078000\n",
      "  Building wheel for pyrsistent (setup.py): started\n",
      "  Building wheel for pyrsistent (setup.py): finished with status 'done'\n",
      "  Created wheel for pyrsistent: filename=pyrsistent-0.17.3-cp37-cp37m-linux_x86_64.whl size=55875 sha256=5981a118987b2a0a2057fb7b4cf1dca9ac0a9176c2b6f2b891befb8093e1ae99\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-s4vr0taf/wheels/a5/52/bf/71258a1d7b3c8cbe1ee53f9314c6f65f20385481eaee573cc5\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-py3-none-any.whl size=19552 sha256=33fadc45125adbd3ad93a7031764ffe5434e318f6cf6d13966a18eb9fb997e89\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-s4vr0taf/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
      "Successfully built tabulate v3iofs kfp adlfs future kfp-server-api strip-hints aiobotocore pandocfilters pyrsistent wrapt\n",
      "Installing collected packages: urllib3, requests, tabulate, typing-extensions, pydantic, zipp, importlib-metadata, fsspec, ujson, future, v3io, v3iofs, orjson, python-dateutil, greenlet, sqlalchemy, python-editor, MarkupSafe, Mako, alembic, mistune, ipython-genutils, traitlets, jupyter-core, defusedxml, jinja2, pygments, entrypoints, pyrsistent, attrs, jsonschema, nbformat, webencodings, pyparsing, packaging, bleach, jupyterlab-pygments, pandocfilters, tornado, nest-asyncio, pyzmq, jupyter-client, async-generator, nbclient, testpath, nbconvert, ptyprocess, terminado, prometheus-client, argon2-cffi, Send2Trash, decorator, backcall, wcwidth, prompt-toolkit, parso, jedi, pickleshare, pexpect, ipython, ipykernel, notebook, jmespath, botocore, s3transfer, boto3, pyyaml, nuclio-jupyter, mergedeep, numpy, pyarrow, humanfriendly, smmap, gitdb, GitPython, grpcio, protobuf, grpcio-tools, pytz, pandas, async-timeout, multidict, yarl, aiohttp, googleapis-common-protos, v3io-frames, storey, click, pyasn1, rsa, pyasn1-modules, cachetools, google-auth, google-crc32c, google-resumable-media, google-api-core, google-cloud-core, google-cloud-storage, websocket-client, oauthlib, requests-oauthlib, kubernetes, requests-toolbelt, cloudpickle, kfp-server-api, wrapt, Deprecated, strip-hints, kfp, sortedcontainers, heapdict, zict, msgpack, psutil, toolz, tblib, dask, distributed, starlette, fastapi, cryptography, semver, aioitertools, aiobotocore, s3fs, azure-core, isodate, msrest, azure-storage-blob, PyJWT, adal, azure-datalake-store, msal, portalocker, msal-extensions, azure-identity, msrestazure, adlfs, mlrun\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.24.1\n",
      "    Uninstalling urllib3-1.24.1:\n",
      "      Successfully uninstalled urllib3-1.24.1\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.21.0\n",
      "    Uninstalling requests-2.21.0:\n",
      "      Successfully uninstalled requests-2.21.0\n",
      "  Attempting uninstall: cryptography\n",
      "    Found existing installation: cryptography 2.6.1\n",
      "    Uninstalling cryptography-2.6.1:\n",
      "      Successfully uninstalled cryptography-2.6.1\n",
      "ERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "google-api-core 1.26.3 requires six>=1.13.0, but you'll have six 1.12.0 which is incompatible.\n",
      "aiobotocore 1.3.0 requires botocore<1.20.50,>=1.20.49, but you'll have botocore 1.19.52 which is incompatible.\n",
      "Successfully installed Deprecated-1.2.12 GitPython-3.1.14 Mako-1.1.4 MarkupSafe-1.1.1 PyJWT-2.0.1 Send2Trash-1.5.0 adal-1.2.7 adlfs-0.7.1 aiobotocore-1.3.0 aiohttp-3.7.4.post0 aioitertools-0.7.1 alembic-1.5.8 argon2-cffi-20.1.0 async-generator-1.10 async-timeout-3.0.1 attrs-20.3.0 azure-core-1.13.0 azure-datalake-store-0.0.52 azure-identity-1.5.0 azure-storage-blob-12.6.0 backcall-0.2.0 bleach-3.3.0 boto3-1.16.52 botocore-1.19.52 cachetools-4.2.1 click-7.1.2 cloudpickle-1.6.0 cryptography-3.3.2 dask-2.30.0 decorator-5.0.6 defusedxml-0.7.1 distributed-2.30.1 entrypoints-0.3 fastapi-0.62.0 fsspec-0.9.0 future-0.18.2 gitdb-4.0.7 google-api-core-1.26.3 google-auth-1.28.1 google-cloud-core-1.6.0 google-cloud-storage-1.37.1 google-crc32c-1.1.2 google-resumable-media-1.2.0 googleapis-common-protos-1.53.0 greenlet-1.0.0 grpcio-1.30.0 grpcio-tools-1.30.0 heapdict-1.0.1 humanfriendly-8.2 importlib-metadata-3.10.0 ipykernel-5.5.3 ipython-7.16.1 ipython-genutils-0.2.0 isodate-0.6.0 jedi-0.18.0 jinja2-2.11.3 jmespath-0.10.0 jsonschema-3.2.0 jupyter-client-6.2.0 jupyter-core-4.7.1 jupyterlab-pygments-0.1.2 kfp-1.0.4 kfp-server-api-1.4.1 kubernetes-11.0.0 mergedeep-1.3.4 mistune-0.8.4 mlrun-0.6.1 msal-1.11.0 msal-extensions-0.3.0 msgpack-1.0.2 msrest-0.6.21 msrestazure-0.6.4 multidict-5.1.0 nbclient-0.5.3 nbconvert-6.0.7 nbformat-5.1.3 nest-asyncio-1.5.1 notebook-6.3.0 nuclio-jupyter-0.8.12 numpy-1.19.5 oauthlib-3.1.0 orjson-3.3.1 packaging-20.9 pandas-1.2.3 pandocfilters-1.4.3 parso-0.8.2 pexpect-4.8.0 pickleshare-0.7.5 portalocker-1.7.1 prometheus-client-0.10.1 prompt-toolkit-3.0.18 protobuf-3.15.8 psutil-5.8.0 ptyprocess-0.7.0 pyarrow-1.0.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 pydantic-1.8.1 pygments-2.8.1 pyparsing-2.4.7 pyrsistent-0.17.3 python-dateutil-2.8.1 python-editor-1.0.4 pytz-2021.1 pyyaml-5.4.1 pyzmq-22.0.3 requests-2.25.1 requests-oauthlib-1.3.0 requests-toolbelt-0.9.1 rsa-4.7.2 s3fs-0.6.0 s3transfer-0.3.6 semver-2.13.0 smmap-4.0.0 sortedcontainers-2.3.0 sqlalchemy-1.4.7 starlette-0.13.6 storey-0.3.8 strip-hints-0.1.9 tabulate-0.8.3 tblib-1.7.0 terminado-0.9.4 testpath-0.4.4 toolz-0.11.1 tornado-6.1 traitlets-5.0.5 typing-extensions-3.7.4.3 ujson-4.0.2 urllib3-1.26.4 v3io-0.5.7 v3io-frames-0.8.14 v3iofs-0.1.6 wcwidth-0.2.5 webencodings-0.5.1 websocket-client-0.58.0 wrapt-1.12.1 yarl-1.6.3 zict-2.0.0 zipp-3.4.1\n",
      "\u001b[36mINFO\u001b[0m[0249] Taking snapshot of full filesystem...        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlrun import new_function\n",
    "#should be converted to an image (spark operator)\n",
    "spark_job = new_function(kind='spark', command='/User/parquez/functions/kv_to_parquet.py', name='kv-to-parquet') # /User isn't supported at this stage\n",
    "project.set_function(spark_job)\n",
    "project.func('kv-to-parquet').with_driver_limits(cpu=\"4000\")\n",
    "project.func('kv-to-parquet').with_driver_requests(cpu=2, mem=\"2g\") # gpu_type & gpus=<number_of_gpus> are supported too\n",
    "project.func('kv-to-parquet').with_executor_limits(cpu=\"4000\")\n",
    "project.func('kv-to-parquet').with_executor_requests(cpu=2, mem=\"2g\")\n",
    "project.func('kv-to-parquet').with_igz_spark() # Adds fuse, daemon & iguazio's jars support\n",
    "project.func('kv-to-parquet').deploy()# Rebuilds the image with MLRun - This is needed in order to support artifact logging etc. This step is too long (~3 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlrun import mount_v3io\n",
    "\n",
    "# create-kv-view\n",
    "project.set_function(\"functions/create_kv_view.py\", 'create-kv-view', kind='job', image=image_name)\n",
    "project.func('create-kv-view').apply(mount_v3io())\n",
    "project.func('create-kv-view').set_env('PYTHONPATH', project_path)\n",
    "project.func('create-kv-view').deploy(with_mlrun=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parquet-add-partition\n",
    "project.set_function(\"functions/parquet_add_partition.py\", 'parquet-add-partition', kind='job', image=image_name)\n",
    "project.func('parquet-add-partition').apply(mount_v3io())\n",
    "project.func('parquet-add-partition').set_env('PYTHONPATH', project_path)\n",
    "project.func('parquet-add-partition').deploy(with_mlrun=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#delete-kv-partition\n",
    "project.set_function(\"functions/delete_kv_partition.py\", 'delete-kv-partition', kind='job', image=image_name)\n",
    "project.func('delete-kv-partition').apply(mount_v3io())\n",
    "project.func('delete-kv-partition').set_env('PYTHONPATH', project_path)\n",
    "project.func('delete-kv-partition').deploy(with_mlrun=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#delete-kv-partition\n",
    "project.set_function(\"functions/delete_historical_retention.py\", 'delete-historical-retention', kind='job', image=image_name)\n",
    "project.func('delete-historical-retention').apply(mount_v3io())\n",
    "project.func('delete-historical-retention').set_env('PYTHONPATH', project_path)\n",
    "project.func('delete-historical-retention').deploy(with_mlrun=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parquetinizer\n",
    "project.set_function(\"functions/parquetinizer.py\", 'parquetinizer', kind='job', image=image_name)\n",
    "project.func('parquetinizer').apply(mount_v3io())\n",
    "project.func('parquetinizer').set_env('PYTHONPATH', project_path)\n",
    "project.func('parquetinizer').deploy(with_mlrun=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-step-create-n-run-ml-pipeline\"></a>\n",
    "## Create and Run a Fully Automated ML Pipeline\n",
    "\n",
    "You're now ready to create a full ML pipeline.\n",
    "This is done by using [Kubeflow Pipelines](https://www.kubeflow.org/docs/pipelines/overview/pipelines-overview/), which is integrated into the Iguazio Data Science Platform.\n",
    "Kubeflow Pipelines is an open-source framework for building and deploying portable, scalable machine-learning workflows based on Docker containers.\n",
    "MLRun leverages this framework to take your existing code and deploy it as steps in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /User/parquez/workflow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {path.join(project_path, 'workflow.py')}\n",
    "\n",
    "from kfp import dsl\n",
    "from mlrun import mount_v3io\n",
    "from os import path\n",
    "import os\n",
    "from mlrun import load_project\n",
    "\n",
    "project_path = path.abspath('./')\n",
    "project = load_project(project_path)\n",
    "PROJECT_NAME = project.name\n",
    "\n",
    "\n",
    "\n",
    "V3IO_ACCESS_KEY = os.environ['V3IO_ACCESS_KEY']\n",
    "V3IO_USERNAME = os.getenv('V3IO_USERNAME')\n",
    "\n",
    "\n",
    "funcs = {}\n",
    "project_path = path.abspath('./')\n",
    "parquez_params = {'view_name':'view_name'\n",
    "         ,'partition_by':'h'\n",
    "         ,'partition_interval':'1h'\n",
    "         ,'real_time_window':'3h'\n",
    "         ,'historical_retention':'24h'\n",
    "         ,'real_time_table_name':'faker'\n",
    "         ,'config_path':'/User/parquez/config/parquez.ini'\n",
    "         ,'user_name':V3IO_USERNAME\n",
    "         ,'access_key':V3IO_ACCESS_KEY          \n",
    "         ,'project_path': PROJECT_NAME\n",
    "         }\n",
    "\n",
    "\n",
    "# Configure function resources and local settings\n",
    "def init_functions(functions: dict, project=None, secrets=None):\n",
    "    project_path = path.abspath('./')\n",
    "    for f in functions.values():\n",
    "        f.apply(mount_v3io())\n",
    "        f.set_env('PYTHONPATH', project_path)\n",
    "        f.spec.artifact_path = 'User/artifacts'\n",
    "        f.spec.service_account='mlrun-api'\n",
    "        \n",
    "        \n",
    "# Create a Kubeflow Pipelines pipeline\n",
    "@dsl.pipeline(\n",
    "    name = \"parquez-pipeline\",\n",
    "    description = \"parquez description\"\n",
    ")\n",
    "def kfpipeline():\n",
    "    \n",
    "    # clean the tables\n",
    "    clean = funcs['clean'].as_step(\n",
    "        name=\"clean\",\n",
    "        params=parquez_params,\n",
    "        outputs=['clean']\n",
    "    )\n",
    "    \n",
    "    # Ingest the data set\n",
    "    validate = funcs['validate'].as_step(\n",
    "        name=\"validate\",\n",
    "        params=parquez_params,\n",
    "        inputs={'table': clean.outputs},\n",
    "        outputs=['validate']\n",
    "    )\n",
    "    \n",
    "    # Analyze the dataset\n",
    "    schema = funcs['get_schema'].as_step(\n",
    "        name=\"get_schema\",\n",
    "        params = parquez_params,\n",
    "        inputs={'table': validate.outputs},                       \n",
    "        outputs=['schema']\n",
    "    )\n",
    "    \n",
    "    parquet = funcs[\"create_parquet\"].as_step(\n",
    "        name=\"create_parquet\",\n",
    "        params=parquez_params,\n",
    "        inputs={\"table\": schema.outputs['schema']},\n",
    "        outputs=['create_parquet']\n",
    "    )\n",
    "    \n",
    "    kv_view = funcs[\"create-kv-view\"].as_step(\n",
    "        name=\"create_kv_view\",\n",
    "        params=parquez_params,\n",
    "        inputs={'table': parquet.outputs},\n",
    "        outputs=['kv_view']\n",
    "    )\n",
    "    \n",
    "    unified_view = funcs[\"create_unified_view\"].as_step(\n",
    "        name=\"create_unified_view\",\n",
    "        params=parquez_params,\n",
    "        inputs={'table': kv_view.outputs},\n",
    "        outputs=['unified_view']\n",
    "    )\n",
    "    \n",
    "    unified_view = funcs[\"run_scheduler\"].as_step(\n",
    "        name=\"run_scheduler\",\n",
    "        params=parquez_params,\n",
    "        inputs={'table': unified_view.outputs},\n",
    "        outputs=['run_scheduler']\n",
    "    )    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-register-workflow\"></a>\n",
    "#### Register the Workflow\n",
    "\n",
    "Use the `set_workflow` MLRun project method to register your workflow with MLRun.\n",
    "The following code sets the `name` parameter to the selected workflow name (\"main\") and the `code` parameter to the name of the workflow file that is found in your project directory (**workflow.py**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the workflow file as \"main\"\n",
    "project.set_workflow('main', 'workflow.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-04-12 12:13:07,799 [info] using in-cluster config.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"https://dashboard.default-tenant.app.dev39.lab.iguazeng.com/pipelines/#/experiments/details/83ff9058-79af-433a-b13b-1bbe3728cd7a\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"https://dashboard.default-tenant.app.dev39.lab.iguazeng.com/pipelines/#/runs/details/fe26a23e-4a8b-4bb6-8e4c-b41bcad75b68\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-04-12 12:13:08,853 [info] Pipeline run id=fe26a23e-4a8b-4bb6-8e4c-b41bcad75b68, check UI or DB for progress\n"
     ]
    }
   ],
   "source": [
    "run_id = project.run(\n",
    "    'main',\n",
    "    arguments={}, \n",
    "    \n",
    "    artifact_path=path.abspath(path.join('pipeline','{{workflow.uid}}'),\n",
    "    \n",
    "                              )\n",
    "    ,dirty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SchedulesOutput(schedules=[])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlrun import get_run_db\n",
    "get_run_db().list_schedules('parquez')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
