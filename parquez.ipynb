{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install colorlog PyHive mlrun kubernetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project path: /User/parquez\n",
      "Project name: parquez\n"
     ]
    }
   ],
   "source": [
    "from os import path, getenv\n",
    "from mlrun import new_project, mlconf\n",
    "\n",
    "#project_name = '-'.join(filter(None, ['getting-started-iris', getenv('V3IO_USERNAME', None)]))\n",
    "project_name = \"parquez\"\n",
    "project_path = path.abspath('./')\n",
    "project = new_project(project_name, project_path)\n",
    "project.save()\n",
    "print(f'Project path: {project_path}\\nProject name: {project_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = mlconf.artifact_path or path.abspath('./data')\n",
    "# {{run.uid}} will be substituted with the run id, so output will be written to different directoried per run\n",
    "artifact_path = path.join(out, '{{run.uid}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONPATH=./\n"
     ]
    }
   ],
   "source": [
    "%env PYTHONPATH=./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.kubejob.KubejobRuntime at 0x7fb2b01080d0>"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.set_function(\"functions/validate_input.py\", 'validate', kind='job', image='aviaigz/parquez')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.kubejob.KubejobRuntime at 0x7fb2b0108d90>"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.set_function(\"functions/get_table_schema.py\", 'get_schema', kind='job', image='aviaigz/parquez')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.kubejob.KubejobRuntime at 0x7fb2b02e8910>"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.set_function(\"functions/create_parquet_table.py\", 'create_parquet', kind='job', image='aviaigz/parquez')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.kubejob.KubejobRuntime at 0x7fb2b04e1ad0>"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.set_function(\"functions/create_kv_view.py\", 'create_kv_view', kind='job', image='aviaigz/parquez')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.kubejob.KubejobRuntime at 0x7fb2b031be50>"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.set_function(\"functions/create_unified_view.py\", 'create_unified_view', kind='job', image='aviaigz/parquez')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2020-07-27 11:44:54,564 [warning] warning!, server (0.4.10) and client (0.5.0) ver dont match\n",
      "> 2020-07-27 11:44:54,566 [debug] saving function: run-parquez-interval, tag: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'a42666cc782bbd959c7563704311fe078786ac7f'"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.set_function(\"functions/run_parquez_interval.py\", 'run_parquez_interval', kind='job', image='aviaigz/parquez')\n",
    "project.func('run_parquez_interval').apply(mount_v3io())\n",
    "project.func('run_parquez_interval').set_env('PYTHONPATH', project_path)\n",
    "project.func('run_parquez_interval').spec.artifact_path = 'User/artifacts'\n",
    "project.func('run_parquez_interval').spec.service_account='mlrun-api'\n",
    "project.func('run_parquez_interval').save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.kubejob.KubejobRuntime at 0x7fb2b0123150>"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.set_function(\"functions/run_scheduler.py\", 'run_scheduler', kind='job', image='aviaigz/parquez')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-step-create-n-run-ml-pipeline\"></a>\n",
    "## Create and Run a Fully Automated ML Pipeline\n",
    "\n",
    "You're now ready to create a full ML pipeline.\n",
    "This is done by using [Kubeflow Pipelines](https://www.kubeflow.org/docs/pipelines/overview/pipelines-overview/), which is integrated into the Iguazio Data Science Platform.\n",
    "Kubeflow Pipelines is an open-source framework for building and deploying portable, scalable machine-learning workflows based on Docker containers.\n",
    "MLRun leverages this framework to take your existing code and deploy it as steps in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /User/parquez/workflow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {path.join(project_path, 'workflow.py')}\n",
    "\n",
    "from kfp import dsl\n",
    "from mlrun import mount_v3io\n",
    "from os import path\n",
    "\n",
    "funcs = {}\n",
    "\n",
    "\n",
    "parquez_params = {'view_name':'view_name'\n",
    "         ,'partition_by':'h'\n",
    "         ,'partition_interval':'1h'\n",
    "         ,'real_time_window':'1d'\n",
    "         ,'historical_retention':'7d'\n",
    "         ,'real_time_table_name':'faker'\n",
    "         ,'config_path':'/User/parquez/config/parquez.ini'}\n",
    "\n",
    "\n",
    "# Configure function resources and local settings\n",
    "def init_functions(functions: dict, project=None, secrets=None):\n",
    "    project_path = path.abspath('./')\n",
    "    for f in functions.values():\n",
    "        f.apply(mount_v3io())\n",
    "        f.set_env('PYTHONPATH', project_path)\n",
    "        f.spec.artifact_path = 'User/artifacts'\n",
    "        f.spec.service_account='mlrun-api'\n",
    "        \n",
    "        \n",
    "# Create a Kubeflow Pipelines pipeline\n",
    "@dsl.pipeline(\n",
    "    name = \"parquez-pipeline\",\n",
    "    description = \"parquez description\"\n",
    ")\n",
    "def kfpipeline():\n",
    "    # Ingest the data set\n",
    "    validate = funcs['validate'].as_step(\n",
    "        name=\"validate\",\n",
    "        params=parquez_params,\n",
    "        outputs=['validate']\n",
    "    )\n",
    "    \n",
    "    # Analyze the dataset\n",
    "    schema = funcs['get_schema'].as_step(\n",
    "        name=\"get_schema\",\n",
    "        params = parquez_params,\n",
    "        inputs={'table': validate.outputs},                       \n",
    "        outputs=['schema']\n",
    "    )\n",
    "    \n",
    "    parquet = funcs[\"create_parquet\"].as_step(\n",
    "        name=\"create_parquet\",\n",
    "        params=parquez_params,\n",
    "        inputs={\"table\": schema.outputs['schema']},\n",
    "        outputs=['create_parquet']\n",
    "    )\n",
    "    \n",
    "    kv_view = funcs[\"create_kv_view\"].as_step(\n",
    "        name=\"create_kv_view\",\n",
    "        params=parquez_params,\n",
    "        inputs={'table': parquet.outputs},\n",
    "        outputs=['kv_view']\n",
    "    )\n",
    "    \n",
    "    unified_view = funcs[\"create_unified_view\"].as_step(\n",
    "        name=\"create_unified_view\",\n",
    "        params=parquez_params,\n",
    "        inputs={'table': kv_view.outputs},\n",
    "        outputs=['unified_view']\n",
    "    )\n",
    "    \n",
    "    unified_view = funcs[\"run_scheduler\"].as_step(\n",
    "        name=\"run_scheduler\",\n",
    "        params=parquez_params,\n",
    "        inputs={'table': unified_view.outputs},\n",
    "        outputs=['run_scheduler']\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-register-workflow\"></a>\n",
    "#### Register the Workflow\n",
    "\n",
    "Use the `set_workflow` MLRun project method to register your workflow with MLRun.\n",
    "The following code sets the `name` parameter to the selected workflow name (\"main\") and the `code` parameter to the name of the workflow file that is found in your project directory (**workflow.py**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the workflow file as \"main\"\n",
    "project.set_workflow('main', 'workflow.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2020-07-27 11:44:54,759 [warning] warning!, server (0.4.10) and client (0.5.0) ver dont match\n",
      "> 2020-07-27 11:44:54,779 [debug] saving function: validate, tag: \n",
      "> 2020-07-27 11:44:54,823 [warning] warning!, server (0.4.10) and client (0.5.0) ver dont match\n",
      "> 2020-07-27 11:44:54,840 [debug] saving function: get-schema, tag: \n",
      "> 2020-07-27 11:44:54,877 [warning] warning!, server (0.4.10) and client (0.5.0) ver dont match\n",
      "> 2020-07-27 11:44:54,892 [debug] saving function: create-parquet, tag: \n",
      "> 2020-07-27 11:44:54,929 [warning] warning!, server (0.4.10) and client (0.5.0) ver dont match\n",
      "> 2020-07-27 11:44:54,945 [debug] saving function: create-kv-view, tag: \n",
      "> 2020-07-27 11:44:54,984 [warning] warning!, server (0.4.10) and client (0.5.0) ver dont match\n",
      "> 2020-07-27 11:44:54,999 [debug] saving function: create-unified-view, tag: \n",
      "> 2020-07-27 11:44:55,037 [warning] warning!, server (0.4.10) and client (0.5.0) ver dont match\n",
      "> 2020-07-27 11:44:55,052 [debug] saving function: run-scheduler, tag: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"https://dashboard.default-tenant.app.app-lab-aws-b1565.iguazio-cd0.com/pipelines/#/experiments/details/3fa69ae1-f9b6-4539-b398-1bd4010080ad\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"https://dashboard.default-tenant.app.app-lab-aws-b1565.iguazio-cd0.com/pipelines/#/runs/details/891ba404-94cc-4373-a3a6-bc2031412053\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2020-07-27 11:44:55,232 [info] Pipeline run id=891ba404-94cc-4373-a3a6-bc2031412053, check UI or DB for progress\n"
     ]
    }
   ],
   "source": [
    "run_id = project.run(\n",
    "    'main',\n",
    "    arguments={}, \n",
    "    \n",
    "    artifact_path=path.abspath(path.join('pipeline','{{workflow.uid}}'),\n",
    "    \n",
    "                              )\n",
    "    ,dirty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
