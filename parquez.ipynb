{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Parquez pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall mlrun -y\n",
    "\n",
    "#!pip install colorlog PyHive mlrun==0.5.1-rc1 kubernetes\n",
    "!pip show mlrun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create the mlrun project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project path: /User/parquez\n",
      "Project name: parquez\n"
     ]
    }
   ],
   "source": [
    "from os import path, getenv\n",
    "from mlrun import new_project, mlconf\n",
    "\n",
    "#project_name = '-'.join(filter(None, ['getting-started-iris', getenv('V3IO_USERNAME', None)]))\n",
    "project_name = \"parquez\"\n",
    "project_path = path.abspath('./')\n",
    "project = new_project(project_name, project_path)\n",
    "project.save()\n",
    "print(f'Project path: {project_path}\\nProject name: {project_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONPATH=./\n"
     ]
    }
   ],
   "source": [
    "out = mlconf.artifact_path or path.abspath('./data')\n",
    "# {{run.uid}} will be substituted with the run id, so output will be written to different directoried per run\n",
    "artifact_path = path.join(out, '{{run.uid}}')\n",
    "%env PYTHONPATH=./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set the project functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.kubejob.KubejobRuntime at 0x7fdac03a6e50>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlrun import mount_v3io\n",
    "#project.set_function(\"functions/clean_parquez.py\", 'clean', kind='job', image='aviaigz/parquez')\n",
    "project.set_function(\"functions/validate_input.py\", 'validate', kind='job', image='aviaigz/parquez')\n",
    "project.set_function(\"functions/get_table_schema.py\", 'get_schema', kind='job', image='aviaigz/parquez')\n",
    "project.set_function(\"functions/create_parquet_table.py\", 'create_parquet', kind='job', image='aviaigz/parquez')\n",
    "project.set_function(\"functions/create_kv_view.py\", 'create_kv_view', kind='job', image='aviaigz/parquez')\n",
    "project.set_function(\"functions/create_unified_view.py\", 'create_unified_view', kind='job', image='aviaigz/parquez')\n",
    "project.set_function(\"functions/run_parquez_interval.py\", 'run_parquez_interval', kind='job', image='aviaigz/parquez')\n",
    "project.func('run_parquez_interval').apply(mount_v3io())\n",
    "project.func('run_parquez_interval').set_env('PYTHONPATH', project_path)\n",
    "project.func('run_parquez_interval').spec.artifact_path = 'User/artifacts'\n",
    "project.func('run_parquez_interval').spec.service_account='mlrun-api'\n",
    "project.func('run_parquez_interval').save()\n",
    "project.set_function(\"functions/run_scheduler.py\", 'run_scheduler', kind='job', image='aviaigz/parquez')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-step-create-n-run-ml-pipeline\"></a>\n",
    "## Create and Run a Fully Automated ML Pipeline\n",
    "\n",
    "You're now ready to create a full ML pipeline.\n",
    "This is done by using [Kubeflow Pipelines](https://www.kubeflow.org/docs/pipelines/overview/pipelines-overview/), which is integrated into the Iguazio Data Science Platform.\n",
    "Kubeflow Pipelines is an open-source framework for building and deploying portable, scalable machine-learning workflows based on Docker containers.\n",
    "MLRun leverages this framework to take your existing code and deploy it as steps in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /User/parquez/workflow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {path.join(project_path, 'workflow.py')}\n",
    "\n",
    "from kfp import dsl\n",
    "from mlrun import mount_v3io\n",
    "from os import path\n",
    "\n",
    "funcs = {}\n",
    "project_path = path.abspath('./')\n",
    "parquez_params = {'view_name':'view_name'\n",
    "         ,'partition_by':'h'\n",
    "         ,'partition_interval':'1h'\n",
    "         ,'real_time_window':'1d'\n",
    "         ,'historical_retention':'7d'\n",
    "         ,'real_time_table_name':'faker'\n",
    "         ,'config_path':'/User/parquez/config/parquez.ini'\n",
    "         ,'project_path': project_path\n",
    "         ,'shell_pod_name' : 'parquez-shell'       }\n",
    "\n",
    "\n",
    "# Configure function resources and local settings\n",
    "def init_functions(functions: dict, project=None, secrets=None):\n",
    "    project_path = path.abspath('./')\n",
    "    for f in functions.values():\n",
    "        f.apply(mount_v3io())\n",
    "        f.set_env('PYTHONPATH', project_path)\n",
    "        f.spec.artifact_path = 'User/artifacts'\n",
    "        f.spec.service_account='mlrun-api'\n",
    "        \n",
    "        \n",
    "# Create a Kubeflow Pipelines pipeline\n",
    "@dsl.pipeline(\n",
    "    name = \"parquez-pipeline\",\n",
    "    description = \"parquez description\"\n",
    ")\n",
    "def kfpipeline():\n",
    "    \n",
    "#     # clean the tables\n",
    "#     clean = funcs['clean'].as_step(\n",
    "#         name=\"clean\",\n",
    "#         params=parquez_params,\n",
    "#         outputs=['clean']\n",
    "#     )\n",
    "    \n",
    "    # Ingest the data set\n",
    "    validate = funcs['validate'].as_step(\n",
    "        name=\"validate\",\n",
    "        params=parquez_params,\n",
    "#         inputs={'table': clean.outputs},\n",
    "        outputs=['validate']\n",
    "    )\n",
    "    \n",
    "    # Analyze the dataset\n",
    "    schema = funcs['get_schema'].as_step(\n",
    "        name=\"get_schema\",\n",
    "        params = parquez_params,\n",
    "        inputs={'table': validate.outputs},                       \n",
    "        outputs=['schema']\n",
    "    )\n",
    "    \n",
    "    parquet = funcs[\"create_parquet\"].as_step(\n",
    "        name=\"create_parquet\",\n",
    "        params=parquez_params,\n",
    "        inputs={\"table\": schema.outputs['schema']},\n",
    "        outputs=['create_parquet']\n",
    "    )\n",
    "    \n",
    "    kv_view = funcs[\"create_kv_view\"].as_step(\n",
    "        name=\"create_kv_view\",\n",
    "        params=parquez_params,\n",
    "        inputs={'table': parquet.outputs},\n",
    "        outputs=['kv_view']\n",
    "    )\n",
    "    \n",
    "    unified_view = funcs[\"create_unified_view\"].as_step(\n",
    "        name=\"create_unified_view\",\n",
    "        params=parquez_params,\n",
    "        inputs={'table': kv_view.outputs},\n",
    "        outputs=['unified_view']\n",
    "    )\n",
    "    \n",
    "    unified_view = funcs[\"run_scheduler\"].as_step(\n",
    "        name=\"run_scheduler\",\n",
    "        params=parquez_params,\n",
    "        inputs={'table': unified_view.outputs},\n",
    "        outputs=['run_scheduler']\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-register-workflow\"></a>\n",
    "#### Register the Workflow\n",
    "\n",
    "Use the `set_workflow` MLRun project method to register your workflow with MLRun.\n",
    "The following code sets the `name` parameter to the selected workflow name (\"main\") and the `code` parameter to the name of the workflow file that is found in your project directory (**workflow.py**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the workflow file as \"main\"\n",
    "project.set_workflow('main', 'workflow.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"https://dashboard.default-tenant.app.app-lab-aws-b1565.iguazio-cd0.com/pipelines/#/experiments/details/3fa69ae1-f9b6-4539-b398-1bd4010080ad\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"https://dashboard.default-tenant.app.app-lab-aws-b1565.iguazio-cd0.com/pipelines/#/runs/details/542a5a61-5eec-4256-941d-bfdc566e8e29\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2020-08-02 14:42:24,572 [info] Pipeline run id=542a5a61-5eec-4256-941d-bfdc566e8e29, check UI or DB for progress\n"
     ]
    }
   ],
   "source": [
    "run_id = project.run(\n",
    "    'main',\n",
    "    arguments={}, \n",
    "    \n",
    "    artifact_path=path.abspath(path.join('pipeline','{{workflow.uid}}'),\n",
    "    \n",
    "                              )\n",
    "    ,dirty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SchedulesOutput(schedules=[])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlrun import get_run_db\n",
    "get_run_db().list_schedules('parquez')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
