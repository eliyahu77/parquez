{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Parquez pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mlrun==0.6.0rc7\n",
    "!pip show mlrun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create the mlrun project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path, getenv\n",
    "from mlrun import new_project, mlconf\n",
    "\n",
    "#project_name = '-'.join(filter(None, ['getting-started-iris', getenv('V3IO_USERNAME', None)]))\n",
    "project_name = \"parquez\"\n",
    "project_path = path.abspath('./')\n",
    "project = new_project(project_name, project_path)\n",
    "project.save()\n",
    "print(f'Project path: {project_path}\\nProject name: {project_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = mlconf.artifact_path or path.abspath('./data')\n",
    "# {{run.uid}} will be substituted with the run id, so output will be written to different directoried per run\n",
    "artifact_path = path.join(out, '{{run.uid}}')\n",
    "%env PYTHONPATH=./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set the project functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.kubejob.KubejobRuntime at 0x7fc6719a9d10>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlrun.run import new_function\n",
    "from mlrun import mount_v3io\n",
    "\n",
    "image_name =  'aviaigz/parquez:0.6.0rc7'\n",
    "\n",
    "project.set_function(\"functions/validate_input.py\", 'validate', kind='job', image=image_name)\n",
    "project.set_function(\"functions/get_table_schema.py\", 'get_schema', kind='job', image=image_name)\n",
    "project.set_function(\"functions/create_parquet_table.py\", 'create_parquet', kind='job', image=image_name)\n",
    "project.set_function(\"functions/create_kv_view.py\", 'create_kv_view', kind='job', image=image_name)\n",
    "project.set_function(\"functions/create_unified_view.py\", 'create_unified_view', kind='job', image=image_name)\n",
    "project.set_function(\"functions/parquet_add_partition.py\", 'parquet_add_partition', kind='job', image=image_name)\n",
    "project.set_function(\"functions/delete_kv_partition.py\", 'delete_kv_partition', kind='job', image=image_name)\n",
    "spark_job = new_function(kind='spark', command='/User/parquez/functions/kv_to_parquet.py', name='kv_to_parquet') # /User isn't supported at this stage\n",
    "project.set_function(spark_job)\n",
    "project.set_function(\"functions/run_scheduler.py\", 'run_scheduler', kind='job', image=image_name)\n",
    "project.set_function(\"functions/parquet_add_partition.py\", 'run_scheduler', kind='job', image=image_name)\n",
    "project.set_function(\"functions/parquetinizer.py\", 'parquetinizer', kind='job', image=image_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-01-11 09:37:47,232 [info] running build to add mlrun package, set with_mlrun=False to skip if its already in the image\n",
      "> 2021-01-11 09:37:47,234 [info] starting remote build, image: .mlrun/func-parquez-kv_to_parquet-latest\n",
      "E0111 09:37:50.495449       1 aws_credentials.go:77] while getting AWS credentials NoCredentialProviders: no valid providers in chain. Deprecated.\n",
      "\tFor verbose messaging see aws.Config.CredentialsChainVerboseErrors\n",
      "E0111 09:37:50.505138       1 metadata.go:154] while reading 'google-dockercfg' metadata: http status code: 404 while fetching url http://metadata.google.internal./computeMetadata/v1/instance/attributes/google-dockercfg\n",
      "E0111 09:37:50.508153       1 metadata.go:166] while reading 'google-dockercfg-url' metadata: http status code: 404 while fetching url http://metadata.google.internal./computeMetadata/v1/instance/attributes/google-dockercfg-url\n",
      "\u001b[36mINFO\u001b[0m[0000] Retrieving image manifest gcr.io/iguazio/spark-app:3.0_b5984_20210102145103 \n",
      "\u001b[36mINFO\u001b[0m[0001] Retrieving image manifest gcr.io/iguazio/spark-app:3.0_b5984_20210102145103 \n",
      "\u001b[36mINFO\u001b[0m[0001] Built cross stage deps: map[]                \n",
      "\u001b[36mINFO\u001b[0m[0001] Retrieving image manifest gcr.io/iguazio/spark-app:3.0_b5984_20210102145103 \n",
      "\u001b[36mINFO\u001b[0m[0001] Retrieving image manifest gcr.io/iguazio/spark-app:3.0_b5984_20210102145103 \n",
      "\u001b[36mINFO\u001b[0m[0001] Executing 0 build triggers                   \n",
      "\u001b[36mINFO\u001b[0m[0001] Unpacking rootfs as cmd RUN pip install mlrun[complete]==0.6.0-rc8 requires it. \n",
      "\u001b[36mINFO\u001b[0m[0050] RUN pip install mlrun[complete]==0.6.0-rc8   \n",
      "\u001b[36mINFO\u001b[0m[0050] Taking snapshot of full filesystem...        \n",
      "\u001b[36mINFO\u001b[0m[0072] cmd: /bin/sh                                 \n",
      "\u001b[36mINFO\u001b[0m[0072] args: [-c pip install mlrun[complete]==0.6.0-rc8] \n",
      "\u001b[36mINFO\u001b[0m[0072] util.Lookup returned: &{Uid:1000 Gid:1000 Username:iguazio Name: HomeDir:/igz} \n",
      "\u001b[36mINFO\u001b[0m[0072] performing slow lookup of group ids for iguazio \n",
      "\u001b[36mINFO\u001b[0m[0072] Running: [/bin/sh -c pip install mlrun[complete]==0.6.0-rc8] \n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting mlrun[complete]==0.6.0-rc8\n",
      "  Downloading mlrun-0.6.0rc8-py3-none-any.whl (313 kB)\n",
      "Collecting nest-asyncio~=1.0\n",
      "  Downloading nest_asyncio-1.4.3-py3-none-any.whl (5.3 kB)\n",
      "Collecting GitPython~=3.0\n",
      "  Downloading GitPython-3.1.12-py3-none-any.whl (159 kB)\n",
      "Collecting v3io-frames~=0.8.5\n",
      "  Downloading v3io_frames-0.8.10-py3-none-any.whl (35 kB)\n",
      "Collecting humanfriendly~=8.2\n",
      "  Downloading humanfriendly-8.2-py2.py3-none-any.whl (86 kB)\n",
      "Collecting orjson<3.4,>=3\n",
      "  Downloading orjson-3.3.1-cp37-cp37m-manylinux2014_x86_64.whl (208 kB)\n",
      "Collecting mergedeep~=1.3\n",
      "  Downloading mergedeep-1.3.1-py3-none-any.whl (6.4 kB)\n",
      "Collecting ipython<7.17,>=5.5\n",
      "  Downloading ipython-7.16.1-py3-none-any.whl (785 kB)\n",
      "Collecting pyyaml~=5.1\n",
      "  Downloading PyYAML-5.3.1.tar.gz (269 kB)\n",
      "Collecting requests~=2.22\n",
      "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "Collecting pyarrow~=1.0\n",
      "  Downloading pyarrow-1.0.1-cp37-cp37m-manylinux2014_x86_64.whl (17.3 MB)\n",
      "Collecting kubernetes~=11.0\n",
      "  Downloading kubernetes-11.0.0-py3-none-any.whl (1.5 MB)\n",
      "Collecting kfp~=1.0.1\n",
      "  Downloading kfp-1.0.4.tar.gz (116 kB)\n",
      "Collecting v3io~=0.5.0\n",
      "  Downloading v3io-0.5.6-py3-none-any.whl (49 kB)\n",
      "Collecting aiohttp~=3.6\n",
      "  Downloading aiohttp-3.7.3-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
      "Collecting nuclio-jupyter>=0.8.9\n",
      "  Downloading nuclio_jupyter-0.8.9-py3-none-any.whl (47 kB)\n",
      "Collecting semver~=2.13\n",
      "  Downloading semver-2.13.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting alembic~=1.4\n",
      "  Downloading alembic-1.4.3-py2.py3-none-any.whl (159 kB)\n",
      "Collecting click~=7.0\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting chardet<4.0,>=3.0.2\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "Collecting distributed<3,>=2.5.2\n",
      "  Downloading distributed-2.30.1-py3-none-any.whl (656 kB)\n",
      "Collecting urllib3<1.27,>=1.25.4\n",
      "  Downloading urllib3-1.26.2-py2.py3-none-any.whl (136 kB)\n",
      "Collecting pandas~=1.0\n",
      "  Downloading pandas-1.2.0-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\n",
      "Collecting tabulate<=0.8.3,>=0.8.0\n",
      "  Downloading tabulate-0.8.3.tar.gz (46 kB)\n",
      "Collecting sqlalchemy~=1.3\n",
      "  Downloading SQLAlchemy-1.3.22-cp37-cp37m-manylinux2010_x86_64.whl (1.3 MB)\n",
      "Collecting dask~=2.12\n",
      "  Downloading dask-2.30.0-py3-none-any.whl (848 kB)\n",
      "Collecting fastapi~=0.62.0\n",
      "  Downloading fastapi-0.62.0-py3-none-any.whl (49 kB)\n",
      "Collecting pydantic~=1.5\n",
      "  Downloading pydantic-1.7.3-cp37-cp37m-manylinux2014_x86_64.whl (9.1 MB)\n",
      "Collecting azure-storage-blob~=12.0; extra == \"complete\"\n",
      "  Downloading azure_storage_blob-12.6.0-py2.py3-none-any.whl (328 kB)\n",
      "Collecting boto3~=1.9; extra == \"complete\"\n",
      "  Downloading boto3-1.16.51-py2.py3-none-any.whl (130 kB)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.5-py3-none-any.whl (63 kB)\n",
      "Collecting grpcio==1.30.0\n",
      "  Downloading grpcio-1.30.0-cp37-cp37m-manylinux2010_x86_64.whl (3.0 MB)\n",
      "Collecting googleapis-common-protos>=1.5.3\n",
      "  Downloading googleapis_common_protos-1.52.0-py2.py3-none-any.whl (100 kB)\n",
      "Collecting grpcio-tools==1.30.0\n",
      "  Downloading grpcio_tools-1.30.0-cp37-cp37m-manylinux2010_x86_64.whl (2.5 MB)\n",
      "Collecting traitlets>=4.2\n",
      "  Downloading traitlets-5.0.5-py3-none-any.whl (100 kB)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/site-packages (from ipython<7.17,>=5.5->mlrun[complete]==0.6.0-rc8) (45.2.0)\n",
      "Collecting jedi>=0.10\n",
      "  Downloading jedi-0.18.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Collecting pygments\n",
      "  Downloading Pygments-2.7.3-py3-none-any.whl (950 kB)\n",
      "Collecting decorator\n",
      "  Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Collecting backcall\n",
      "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting pickleshare\n",
      "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
      "Collecting pexpect; sys_platform != \"win32\"\n",
      "  Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
      "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
      "  Downloading prompt_toolkit-3.0.10-py3-none-any.whl (355 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2020.12.5-py2.py3-none-any.whl (147 kB)\n",
      "Collecting idna<3,>=2.5\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Collecting numpy>=1.14\n",
      "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
      "Collecting six>=1.9.0\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting google-auth>=1.0.1\n",
      "  Downloading google_auth-1.24.0-py2.py3-none-any.whl (114 kB)\n",
      "Collecting requests-oauthlib\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0\n",
      "  Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\n",
      "Collecting python-dateutil>=2.5.3\n",
      "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Collecting google-cloud-storage>=1.13.0\n",
      "  Downloading google_cloud_storage-1.35.0-py2.py3-none-any.whl (96 kB)\n",
      "Collecting requests_toolbelt>=0.8.0\n",
      "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
      "Collecting cloudpickle\n",
      "  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
      "Collecting kfp-server-api<2.0.0,>=0.2.5\n",
      "  Downloading kfp-server-api-1.3.0.tar.gz (54 kB)\n",
      "Collecting jsonschema>=3.0.1\n",
      "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
      "Collecting Deprecated\n",
      "  Downloading Deprecated-1.2.10-py2.py3-none-any.whl (8.7 kB)\n",
      "Collecting strip-hints\n",
      "  Downloading strip-hints-0.1.9.tar.gz (30 kB)\n",
      "Collecting ujson>=3.0.0\n",
      "  Downloading ujson-4.0.1-cp37-cp37m-manylinux1_x86_64.whl (179 kB)\n",
      "Collecting future>=0.18.2\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "Collecting async-timeout<4.0,>=3.0\n",
      "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142 kB)\n",
      "Collecting typing-extensions>=3.6.5\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting attrs>=17.3.0\n",
      "  Downloading attrs-20.3.0-py2.py3-none-any.whl (49 kB)\n",
      "Collecting nbconvert>=5.4\n",
      "  Downloading nbconvert-6.0.7-py3-none-any.whl (552 kB)\n",
      "Collecting notebook>=5.2.0\n",
      "  Downloading notebook-6.1.6-py3-none-any.whl (9.5 MB)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.1.3-py2.py3-none-any.whl (75 kB)\n",
      "Collecting python-editor>=0.3\n",
      "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
      "Collecting toolz>=0.8.2\n",
      "  Downloading toolz-0.11.1-py3-none-any.whl (55 kB)\n",
      "Collecting msgpack>=0.6.0\n",
      "  Downloading msgpack-1.0.2-cp37-cp37m-manylinux1_x86_64.whl (273 kB)\n",
      "Collecting tornado>=5; python_version < \"3.8\"\n",
      "  Downloading tornado-6.1-cp37-cp37m-manylinux2010_x86_64.whl (428 kB)\n",
      "Collecting psutil>=5.0\n",
      "  Downloading psutil-5.8.0-cp37-cp37m-manylinux2010_x86_64.whl (296 kB)\n",
      "Collecting zict>=0.1.3\n",
      "  Downloading zict-2.0.0-py3-none-any.whl (10 kB)\n",
      "Collecting tblib>=1.6.0\n",
      "  Downloading tblib-1.7.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting sortedcontainers!=2.0.0,!=2.0.1\n",
      "  Downloading sortedcontainers-2.3.0-py2.py3-none-any.whl (29 kB)\n",
      "Collecting pytz>=2017.3\n",
      "  Downloading pytz-2020.5-py2.py3-none-any.whl (510 kB)\n",
      "Collecting starlette==0.13.6\n",
      "  Downloading starlette-0.13.6-py3-none-any.whl (59 kB)\n",
      "Collecting cryptography>=2.1.4\n",
      "  Downloading cryptography-3.3.1-cp36-abi3-manylinux2010_x86_64.whl (2.6 MB)\n",
      "Collecting msrest>=0.6.10\n",
      "  Downloading msrest-0.6.19-py2.py3-none-any.whl (84 kB)\n",
      "Collecting azure-core<2.0.0,>=1.9.0\n",
      "  Downloading azure_core-1.9.0-py2.py3-none-any.whl (124 kB)\n",
      "Collecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting botocore<1.20.0,>=1.19.51\n",
      "  Downloading botocore-1.19.51-py2.py3-none-any.whl (7.2 MB)\n",
      "Collecting s3transfer<0.4.0,>=0.3.0\n",
      "  Downloading s3transfer-0.3.3-py2.py3-none-any.whl (69 kB)\n",
      "Collecting smmap<4,>=3.0.1\n",
      "  Downloading smmap-3.0.4-py2.py3-none-any.whl (25 kB)\n",
      "Collecting protobuf>=3.6.0\n",
      "  Downloading protobuf-3.14.0-cp37-cp37m-manylinux1_x86_64.whl (1.0 MB)\n",
      "Collecting ipython-genutils\n",
      "  Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting parso<0.9.0,>=0.8.0\n",
      "  Downloading parso-0.8.1-py2.py3-none-any.whl (93 kB)\n",
      "Collecting ptyprocess>=0.5\n",
      "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting wcwidth\n",
      "  Downloading wcwidth-0.2.5-py2.py3-none-any.whl (30 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Downloading rsa-4.7-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.0-py3-none-any.whl (12 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting google-cloud-core<2.0dev,>=1.4.1\n",
      "  Downloading google_cloud_core-1.5.0-py2.py3-none-any.whl (27 kB)\n",
      "Collecting google-resumable-media<2.0dev,>=1.2.0\n",
      "  Downloading google_resumable_media-1.2.0-py2.py3-none-any.whl (75 kB)\n",
      "Collecting importlib-metadata; python_version < \"3.8\"\n",
      "  Downloading importlib_metadata-3.4.0-py3-none-any.whl (10 kB)\n",
      "Collecting pyrsistent>=0.14.0\n",
      "  Downloading pyrsistent-0.17.3.tar.gz (106 kB)\n",
      "Collecting wrapt<2,>=1.10\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.7/site-packages (from strip-hints->kfp~=1.0.1->mlrun[complete]==0.6.0-rc8) (0.34.2)\n",
      "Collecting nbclient<0.6.0,>=0.5.0\n",
      "  Downloading nbclient-0.5.1-py3-none-any.whl (65 kB)\n",
      "Collecting entrypoints>=0.2.2\n",
      "  Downloading entrypoints-0.3-py2.py3-none-any.whl (11 kB)\n",
      "Collecting jinja2>=2.4\n",
      "  Downloading Jinja2-2.11.2-py2.py3-none-any.whl (125 kB)\n",
      "Collecting nbformat>=4.4\n",
      "  Downloading nbformat-5.0.8-py3-none-any.whl (172 kB)\n",
      "Collecting defusedxml\n",
      "  Downloading defusedxml-0.6.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting jupyterlab-pygments\n",
      "  Downloading jupyterlab_pygments-0.1.2-py2.py3-none-any.whl (4.6 kB)\n",
      "Collecting mistune<2,>=0.8.1\n",
      "  Downloading mistune-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting bleach\n",
      "  Downloading bleach-3.2.1-py2.py3-none-any.whl (145 kB)\n",
      "Collecting testpath\n",
      "  Downloading testpath-0.4.4-py2.py3-none-any.whl (163 kB)\n",
      "Collecting jupyter-core\n",
      "  Downloading jupyter_core-4.7.0-py3-none-any.whl (82 kB)\n",
      "Collecting pandocfilters>=1.4.1\n",
      "  Downloading pandocfilters-1.4.3.tar.gz (16 kB)\n",
      "Collecting ipykernel\n",
      "  Downloading ipykernel-5.4.2-py3-none-any.whl (119 kB)\n",
      "Collecting argon2-cffi\n",
      "  Downloading argon2_cffi-20.1.0-cp35-abi3-manylinux1_x86_64.whl (97 kB)\n",
      "Collecting pyzmq>=17\n",
      "  Downloading pyzmq-20.0.0-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
      "Collecting jupyter-client>=5.3.4\n",
      "  Downloading jupyter_client-6.1.11-py3-none-any.whl (108 kB)\n",
      "Collecting Send2Trash\n",
      "  Downloading Send2Trash-1.5.0-py3-none-any.whl (12 kB)\n",
      "Collecting terminado>=0.8.3\n",
      "  Downloading terminado-0.9.2-py3-none-any.whl (14 kB)\n",
      "Collecting prometheus-client\n",
      "  Downloading prometheus_client-0.9.0-py2.py3-none-any.whl (53 kB)\n",
      "Collecting MarkupSafe>=0.9.2\n",
      "  Downloading MarkupSafe-1.1.1-cp37-cp37m-manylinux1_x86_64.whl (27 kB)\n",
      "Collecting heapdict\n",
      "  Downloading HeapDict-1.0.1-py3-none-any.whl (3.9 kB)\n",
      "Collecting cffi>=1.12\n",
      "  Downloading cffi-1.14.4-cp37-cp37m-manylinux1_x86_64.whl (402 kB)\n",
      "Collecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting google-api-core<2.0.0dev,>=1.21.0\n",
      "  Downloading google_api_core-1.24.1-py2.py3-none-any.whl (92 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\"\n",
      "  Downloading google_crc32c-1.1.0-cp37-cp37m-manylinux2010_x86_64.whl (39 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.4.0-py3-none-any.whl (5.2 kB)\n",
      "Collecting async-generator\n",
      "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
      "Collecting packaging\n",
      "  Downloading packaging-20.8-py2.py3-none-any.whl (39 kB)\n",
      "Collecting webencodings\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "Collecting pyparsing>=2.0.2\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Building wheels for collected packages: pyyaml, kfp, tabulate, kfp-server-api, strip-hints, future, pyrsistent, wrapt, pandocfilters\n",
      "  Building wheel for pyyaml (setup.py): started\n",
      "  Building wheel for pyyaml (setup.py): finished with status 'done'\n",
      "  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl size=44619 sha256=028589b44fefd61fb41ad7cfe377ac77ab53d22d5275f89d4755912ea9ee105f\n",
      "  Stored in directory: /igz/.cache/pip/wheels/5e/03/1e/e1e954795d6f35dfc7b637fe2277bff021303bd9570ecea653\n",
      "  Building wheel for kfp (setup.py): started\n",
      "  Building wheel for kfp (setup.py): finished with status 'done'\n",
      "  Created wheel for kfp: filename=kfp-1.0.4-py3-none-any.whl size=159872 sha256=69906f9c9798d53caa218a102323b7c93f6bc3d99ecc5b0e8b092af6f2542210\n",
      "  Stored in directory: /igz/.cache/pip/wheels/65/1c/be/3d7366d2288bf1587e4fe6cd0c1ebdce5e3bada21b70a29e66\n",
      "  Building wheel for tabulate (setup.py): started\n",
      "  Building wheel for tabulate (setup.py): finished with status 'done'\n",
      "  Created wheel for tabulate: filename=tabulate-0.8.3-py3-none-any.whl size=23378 sha256=7d2df7f5d4e187c6bd2f35b9081caca925876f0725f1b1defabf6f6c0d6fe8d5\n",
      "  Stored in directory: /igz/.cache/pip/wheels/b8/a2/a6/812a8a9735b090913e109133c7c20aaca4cf07e8e18837714f\n",
      "  Building wheel for kfp-server-api (setup.py): started\n",
      "  Building wheel for kfp-server-api (setup.py): finished with status 'done'\n",
      "  Created wheel for kfp-server-api: filename=kfp_server_api-1.3.0-py3-none-any.whl size=108019 sha256=149dd66a4e931727b2c283fec1a09046bd70229afeed3e478fa204352b14d96e\n",
      "  Stored in directory: /igz/.cache/pip/wheels/40/c1/57/7c3f9134d56eda563ad945a904e9e2edbd22479b292558659e\n",
      "  Building wheel for strip-hints (setup.py): started\n",
      "  Building wheel for strip-hints (setup.py): finished with status 'done'\n",
      "  Created wheel for strip-hints: filename=strip_hints-0.1.9-py2.py3-none-any.whl size=20993 sha256=94622a5221e40c545ff1b9ff4ae61dcbb8bcfca590244c1f75219b152d908adc\n",
      "  Stored in directory: /igz/.cache/pip/wheels/2d/b8/4e/a3ec111d2db63cec88121bd7c0ab1a123bce3b55dd19dda5c1\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491058 sha256=59ae8a122ac975218627331208ab4d86ef396ca267c3b17d271e19bfc0b1f0c9\n",
      "  Stored in directory: /igz/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
      "  Building wheel for pyrsistent (setup.py): started\n",
      "  Building wheel for pyrsistent (setup.py): finished with status 'done'\n",
      "  Created wheel for pyrsistent: filename=pyrsistent-0.17.3-cp37-cp37m-linux_x86_64.whl size=55874 sha256=73d01c93565dacef3c2f3cae07392016cf26516ac16a379fd2eb746005271f71\n",
      "  Stored in directory: /igz/.cache/pip/wheels/a5/52/bf/71258a1d7b3c8cbe1ee53f9314c6f65f20385481eaee573cc5\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-py3-none-any.whl size=19553 sha256=0f68649404a6be754f02d2925b272730095136dcdbb9034a0d1e181cc4a0cecf\n",
      "  Stored in directory: /igz/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
      "  Building wheel for pandocfilters (setup.py): started\n",
      "  Building wheel for pandocfilters (setup.py): finished with status 'done'\n",
      "  Created wheel for pandocfilters: filename=pandocfilters-1.4.3-py3-none-any.whl size=7991 sha256=48cb0d9f597f3da039cf7b7d3946df777d2281aee4a973fedf658990d337e793\n",
      "  Stored in directory: /igz/.cache/pip/wheels/42/81/34/545dc2fbf0e9137811e901108d37fc04650e81d48f97078000\n",
      "Successfully built pyyaml kfp tabulate kfp-server-api strip-hints future pyrsistent wrapt pandocfilters\n",
      "Installing collected packages: nest-asyncio, smmap, gitdb, GitPython, six, python-dateutil, numpy, pytz, pandas, grpcio, protobuf, googleapis-common-protos, grpcio-tools, urllib3, certifi, chardet, idna, requests, v3io-frames, humanfriendly, orjson, mergedeep, ipython-genutils, traitlets, parso, jedi, pygments, decorator, backcall, pickleshare, ptyprocess, pexpect, wcwidth, prompt-toolkit, ipython, pyyaml, pyarrow, pyasn1, pyasn1-modules, rsa, cachetools, google-auth, oauthlib, requests-oauthlib, websocket-client, kubernetes, google-api-core, google-cloud-core, pycparser, cffi, google-crc32c, google-resumable-media, google-cloud-storage, requests-toolbelt, cloudpickle, kfp-server-api, attrs, zipp, typing-extensions, importlib-metadata, pyrsistent, jsonschema, tabulate, click, wrapt, Deprecated, strip-hints, kfp, ujson, future, v3io, async-timeout, multidict, yarl, aiohttp, jmespath, botocore, s3transfer, boto3, jupyter-core, pyzmq, tornado, jupyter-client, async-generator, nbformat, nbclient, entrypoints, MarkupSafe, jinja2, defusedxml, jupyterlab-pygments, mistune, pyparsing, packaging, webencodings, bleach, testpath, pandocfilters, nbconvert, ipykernel, argon2-cffi, Send2Trash, terminado, prometheus-client, notebook, nuclio-jupyter, semver, Mako, python-editor, sqlalchemy, alembic, toolz, msgpack, psutil, heapdict, zict, dask, tblib, sortedcontainers, distributed, starlette, pydantic, fastapi, cryptography, isodate, msrest, azure-core, azure-storage-blob, mlrun\n",
      "  WARNING: The scripts f2py, f2py3 and f2py3.7 are installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script chardetect is installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script humanfriendly is installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script pygmentize is installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts iptest, iptest3, ipython and ipython3 are installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script plasma_store is installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts pyrsa-decrypt, pyrsa-encrypt, pyrsa-keygen, pyrsa-priv2pub, pyrsa-sign and pyrsa-verify are installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script jsonschema is installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tabulate is installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script strip-hints is installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts dsl-compile and kfp are installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts futurize and pasteurize are installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts jupyter, jupyter-migrate and jupyter-troubleshoot are installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts jupyter-kernel, jupyter-kernelspec and jupyter-run are installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script jupyter-trust is installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script jupyter-nbconvert is installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts jupyter-bundlerextension, jupyter-nbextension, jupyter-notebook and jupyter-serverextension are installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script nuclio is installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script pysemver is installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script mako-render is installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script alembic is installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts dask-scheduler, dask-ssh and dask-worker are installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script mlrun is installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "Successfully installed Deprecated-1.2.10 GitPython-3.1.12 Mako-1.1.3 MarkupSafe-1.1.1 Send2Trash-1.5.0 aiohttp-3.7.3 alembic-1.4.3 argon2-cffi-20.1.0 async-generator-1.10 async-timeout-3.0.1 attrs-20.3.0 azure-core-1.9.0 azure-storage-blob-12.6.0 backcall-0.2.0 bleach-3.2.1 boto3-1.16.51 botocore-1.19.51 cachetools-4.2.0 certifi-2020.12.5 cffi-1.14.4 chardet-3.0.4 click-7.1.2 cloudpickle-1.6.0 cryptography-3.3.1 dask-2.30.0 decorator-4.4.2 defusedxml-0.6.0 distributed-2.30.1 entrypoints-0.3 fastapi-0.62.0 future-0.18.2 gitdb-4.0.5 google-api-core-1.24.1 google-auth-1.24.0 google-cloud-core-1.5.0 google-cloud-storage-1.35.0 google-crc32c-1.1.0 google-resumable-media-1.2.0 googleapis-common-protos-1.52.0 grpcio-1.30.0 grpcio-tools-1.30.0 heapdict-1.0.1 humanfriendly-8.2 idna-2.10 importlib-metadata-3.4.0 ipykernel-5.4.2 ipython-7.16.1 ipython-genutils-0.2.0 isodate-0.6.0 jedi-0.18.0 jinja2-2.11.2 jmespath-0.10.0 jsonschema-3.2.0 jupyter-client-6.1.11 jupyter-core-4.7.0 jupyterlab-pygments-0.1.2 kfp-1.0.4 kfp-server-api-1.3.0 kubernetes-11.0.0 mergedeep-1.3.1 mistune-0.8.4 mlrun-0.6.0rc8 msgpack-1.0.2 msrest-0.6.19 multidict-5.1.0 nbclient-0.5.1 nbconvert-6.0.7 nbformat-5.0.8 nest-asyncio-1.4.3 notebook-6.1.6 nuclio-jupyter-0.8.9 numpy-1.19.5 oauthlib-3.1.0 orjson-3.3.1 packaging-20.8 pandas-1.2.0 pandocfilters-1.4.3 parso-0.8.1 pexpect-4.8.0 pickleshare-0.7.5 prometheus-client-0.9.0 prompt-toolkit-3.0.10 protobuf-3.14.0 psutil-5.8.0 ptyprocess-0.7.0 pyarrow-1.0.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycparser-2.20 pydantic-1.7.3 pygments-2.7.3 pyparsing-2.4.7 pyrsistent-0.17.3 python-dateutil-2.8.1 python-editor-1.0.4 pytz-2020.5 pyyaml-5.3.1 pyzmq-20.0.0 requests-2.25.1 requests-oauthlib-1.3.0 requests-toolbelt-0.9.1 rsa-4.7 s3transfer-0.3.3 semver-2.13.0 six-1.15.0 smmap-3.0.4 sortedcontainers-2.3.0 sqlalchemy-1.3.22 starlette-0.13.6 strip-hints-0.1.9 tabulate-0.8.3 tblib-1.7.0 terminado-0.9.2 testpath-0.4.4 toolz-0.11.1 tornado-6.1 traitlets-5.0.5 typing-extensions-3.7.4.3 ujson-4.0.1 urllib3-1.26.2 v3io-0.5.6 v3io-frames-0.8.10 wcwidth-0.2.5 webencodings-0.5.1 websocket-client-0.57.0 wrapt-1.12.1 yarl-1.6.3 zict-2.0.0 zipp-3.4.0\n",
      "WARNING: You are using pip version 20.2.4; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\n",
      "\u001b[36mINFO\u001b[0m[0128] Taking snapshot of full filesystem...        \n",
      "E0111 09:40:26.923508       1 metadata.go:154] while reading 'google-dockercfg' metadata: http status code: 404 while fetching url http://metadata.google.internal./computeMetadata/v1/instance/attributes/google-dockercfg\n",
      "E0111 09:40:26.927203       1 metadata.go:166] while reading 'google-dockercfg-url' metadata: http status code: 404 while fetching url http://metadata.google.internal./computeMetadata/v1/instance/attributes/google-dockercfg-url\n",
      "> 2021-01-11 09:40:56,255 [info] running build to add mlrun package, set with_mlrun=False to skip if its already in the image\n",
      "> 2021-01-11 09:40:56,257 [info] starting remote build, image: .mlrun/func-parquez-delete-kv-partition-latest\n",
      "> 2021-01-11 09:40:56,487 [info] running build to add mlrun package, set with_mlrun=False to skip if its already in the image\n",
      "> 2021-01-11 09:40:56,488 [info] starting remote build, image: .mlrun/func-parquez-parquet-add-partition-latest\n",
      "> 2021-01-11 09:40:56,660 [info] running build to add mlrun package, set with_mlrun=False to skip if its already in the image\n",
      "> 2021-01-11 09:40:56,662 [info] starting remote build, image: .mlrun/func-parquez-create-kv-view-latest\n",
      "> 2021-01-11 09:40:56,837 [info] running build to add mlrun package, set with_mlrun=False to skip if its already in the image\n",
      "> 2021-01-11 09:40:56,839 [info] starting remote build, image: .mlrun/func-parquez-parquetinizer-latest\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "project.func('kv_to_parquet').with_driver_limits(cpu=\"1300m\")\n",
    "project.func('kv_to_parquet').with_driver_requests(cpu=1, mem=\"512m\") # gpu_type & gpus=<number_of_gpus> are supported too\n",
    "project.func('kv_to_parquet').with_executor_limits(cpu=\"1400m\")\n",
    "project.func('kv_to_parquet').with_executor_requests(cpu=1, mem=\"512m\")\n",
    "project.func('kv_to_parquet').with_igz_spark() # Adds fuse, daemon & iguazio's jars support\n",
    "project.func('kv_to_parquet').deploy()# Rebuilds the image with MLRun - This is needed in order to support artifact logging etc. This step is too long (~3 minutes)\n",
    "project.func('delete_kv_partition').deploy() \n",
    "project.func('parquet_add_partition').deploy()\n",
    "project.func('create_kv_view').deploy()\n",
    "project.func('parquetinizer').deploy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-step-create-n-run-ml-pipeline\"></a>\n",
    "## Create and Run a Fully Automated ML Pipeline\n",
    "\n",
    "You're now ready to create a full ML pipeline.\n",
    "This is done by using [Kubeflow Pipelines](https://www.kubeflow.org/docs/pipelines/overview/pipelines-overview/), which is integrated into the Iguazio Data Science Platform.\n",
    "Kubeflow Pipelines is an open-source framework for building and deploying portable, scalable machine-learning workflows based on Docker containers.\n",
    "MLRun leverages this framework to take your existing code and deploy it as steps in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /User/parquez/workflow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {path.join(project_path, 'workflow.py')}\n",
    "\n",
    "from kfp import dsl\n",
    "from mlrun import mount_v3io\n",
    "from os import path\n",
    "import os\n",
    "\n",
    "V3IO_ACCESS_KEY = os.environ['V3IO_ACCESS_KEY']\n",
    "V3IO_USERNAME = os.getenv('V3IO_USERNAME')\n",
    "\n",
    "funcs = {}\n",
    "project_path = path.abspath('./')\n",
    "parquez_params = {'view_name':'view_name'\n",
    "         ,'partition_by':'h'\n",
    "         ,'partition_interval':'1h'\n",
    "         ,'real_time_window':'3h'\n",
    "         ,'historical_retention':'24h'\n",
    "         ,'real_time_table_name':'faker'\n",
    "         ,'config_path':'/User/parquez/config/parquez.ini'\n",
    "         ,'user_name':V3IO_USERNAME\n",
    "         ,'access_key':V3IO_ACCESS_KEY          \n",
    "         ,'project_path': project_path\n",
    "         }\n",
    "\n",
    "\n",
    "# Configure function resources and local settings\n",
    "def init_functions(functions: dict, project=None, secrets=None):\n",
    "    project_path = path.abspath('./')\n",
    "    for f in functions.values():\n",
    "        f.apply(mount_v3io())\n",
    "        f.set_env('PYTHONPATH', project_path)\n",
    "        f.spec.artifact_path = 'User/artifacts'\n",
    "        f.spec.service_account='mlrun-api'\n",
    "        \n",
    "        \n",
    "# Create a Kubeflow Pipelines pipeline\n",
    "@dsl.pipeline(\n",
    "    name = \"parquez-pipeline\",\n",
    "    description = \"parquez description\"\n",
    ")\n",
    "def kfpipeline():\n",
    "    \n",
    "#     # clean the tables\n",
    "#     clean = funcs['clean'].as_step(\n",
    "#         name=\"clean\",\n",
    "#         params=parquez_params,\n",
    "#         outputs=['clean']\n",
    "#     )\n",
    "    \n",
    "    # Ingest the data set\n",
    "    validate = funcs['validate'].as_step(\n",
    "        name=\"validate\",\n",
    "        params=parquez_params,\n",
    "#         inputs={'table': clean.outputs},\n",
    "        outputs=['validate']\n",
    "    )\n",
    "    \n",
    "    # Analyze the dataset\n",
    "    schema = funcs['get_schema'].as_step(\n",
    "        name=\"get_schema\",\n",
    "        params = parquez_params,\n",
    "        inputs={'table': validate.outputs},                       \n",
    "        outputs=['schema']\n",
    "    )\n",
    "    \n",
    "    parquet = funcs[\"create_parquet\"].as_step(\n",
    "        name=\"create_parquet\",\n",
    "        params=parquez_params,\n",
    "        inputs={\"table\": schema.outputs['schema']},\n",
    "        outputs=['create_parquet']\n",
    "    )\n",
    "    \n",
    "    kv_view = funcs[\"create_kv_view\"].as_step(\n",
    "        name=\"create_kv_view\",\n",
    "        params=parquez_params,\n",
    "        inputs={'table': parquet.outputs},\n",
    "        outputs=['kv_view']\n",
    "    )\n",
    "    \n",
    "    unified_view = funcs[\"create_unified_view\"].as_step(\n",
    "        name=\"create_unified_view\",\n",
    "        params=parquez_params,\n",
    "        inputs={'table': kv_view.outputs},\n",
    "        outputs=['unified_view']\n",
    "    )\n",
    "    \n",
    "    unified_view = funcs[\"run_scheduler\"].as_step(\n",
    "        name=\"run_scheduler\",\n",
    "        params=parquez_params,\n",
    "        inputs={'table': unified_view.outputs},\n",
    "        outputs=['run_scheduler']\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-register-workflow\"></a>\n",
    "#### Register the Workflow\n",
    "\n",
    "Use the `set_workflow` MLRun project method to register your workflow with MLRun.\n",
    "The following code sets the `name` parameter to the selected workflow name (\"main\") and the `code` parameter to the name of the workflow file that is found in your project directory (**workflow.py**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the workflow file as \"main\"\n",
    "project.set_workflow('main', 'workflow.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-01-05 15:14:27,637 [info] using in-cluster config.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"https://dashboard.default-tenant.app.gcp-gke-1.iguazio-cd0.com/pipelines/#/experiments/details/ae4f332f-bee5-47d6-b415-943f4877a7e4\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"https://dashboard.default-tenant.app.gcp-gke-1.iguazio-cd0.com/pipelines/#/runs/details/32d412df-4a0d-4bfe-8051-4a05b3b96b75\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-01-05 15:14:30,298 [info] Pipeline run id=32d412df-4a0d-4bfe-8051-4a05b3b96b75, check UI or DB for progress\n"
     ]
    }
   ],
   "source": [
    "run_id = project.run(\n",
    "    'main',\n",
    "    arguments={}, \n",
    "    \n",
    "    artifact_path=path.abspath(path.join('pipeline','{{workflow.uid}}'),\n",
    "    \n",
    "                              )\n",
    "    ,dirty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import get_run_db\n",
    "get_run_db().list_schedules('parquez')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
