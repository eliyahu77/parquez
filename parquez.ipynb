{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Parquez pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both server & client are aligned (0.6.0rc12).\n"
     ]
    }
   ],
   "source": [
    "!/User/align_mlrun.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create the mlrun project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project path: /User/parquez\n",
      "Project name: parquez\n"
     ]
    }
   ],
   "source": [
    "from os import path, getenv\n",
    "from mlrun import new_project, mlconf\n",
    "\n",
    "#project_name = '-'.join(filter(None, ['getting-started-iris', getenv('V3IO_USERNAME', None)]))\n",
    "project_name = \"parquez\"\n",
    "project_path = path.abspath('./')\n",
    "project = new_project(project_name, project_path)\n",
    "project.save()\n",
    "print(f'Project path: {project_path}\\nProject name: {project_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONPATH=./\n"
     ]
    }
   ],
   "source": [
    "out = mlconf.artifact_path or path.abspath('./data')\n",
    "# {{run.uid}} will be substituted with the run id, so output will be written to different directoried per run\n",
    "artifact_path = path.join(out, '{{run.uid}}')\n",
    "%env PYTHONPATH=./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set the project functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.kubejob.KubejobRuntime at 0x7fa1274cd550>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_name =  'aviaigz/parquez:0.6.0-rc12'\n",
    "\n",
    "project.set_function(\"functions/validate_input.py\", 'validate', kind='job', image=image_name)\n",
    "project.set_function(\"functions/get_table_schema.py\", 'get_schema', kind='job', image=image_name)\n",
    "project.set_function(\"functions/create_parquet_table.py\", 'create_parquet', kind='job', image=image_name)\n",
    "project.set_function(\"functions/create_unified_view.py\", 'create_unified_view', kind='job', image=image_name)\n",
    "project.set_function(\"functions/parquet_add_partition.py\", 'parquet_add_partition', kind='job', image=image_name)\n",
    "project.set_function(\"functions/delete_kv_partition.py\", 'delete_kv_partition', kind='job', image=image_name)\n",
    "project.set_function(\"functions/run_scheduler.py\", 'run_scheduler', kind='job', image=image_name)\n",
    "project.set_function(\"functions/parquetinizer.py\", 'parquetinizer', kind='job', image=image_name)\n",
    "project.set_function(\"functions/run_scheduler.py\", 'run_scheduler', kind='job', image=image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deploy kv-to-parquet function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-02-09 13:46:06,062 [info] running build to add mlrun package, set with_mlrun=False to skip if its already in the image\n",
      "> 2021-02-09 13:46:06,063 [info] starting remote build, image: .mlrun/func-parquez-kv-to-parquet-latest\n",
      "\u001b[36mINFO\u001b[0m[0000] Retrieving image manifest gcr.io/iguazio/spark-app:3.0_b5963_20201228195115 \n",
      "\u001b[36mINFO\u001b[0m[0000] Retrieving image manifest gcr.io/iguazio/spark-app:3.0_b5963_20201228195115 \n",
      "\u001b[36mINFO\u001b[0m[0001] Built cross stage deps: map[]                \n",
      "\u001b[36mINFO\u001b[0m[0001] Retrieving image manifest gcr.io/iguazio/spark-app:3.0_b5963_20201228195115 \n",
      "\u001b[36mINFO\u001b[0m[0001] Retrieving image manifest gcr.io/iguazio/spark-app:3.0_b5963_20201228195115 \n",
      "\u001b[36mINFO\u001b[0m[0001] Executing 0 build triggers                   \n",
      "\u001b[36mINFO\u001b[0m[0001] Unpacking rootfs as cmd RUN pip install \"mlrun[complete]==0.6.0-rc12\" requires it. \n",
      "\u001b[36mINFO\u001b[0m[0052] RUN pip install \"mlrun[complete]==0.6.0-rc12\" \n",
      "\u001b[36mINFO\u001b[0m[0052] Taking snapshot of full filesystem...        \n",
      "\u001b[36mINFO\u001b[0m[0058] cmd: /bin/sh                                 \n",
      "\u001b[36mINFO\u001b[0m[0058] args: [-c pip install \"mlrun[complete]==0.6.0-rc12\"] \n",
      "\u001b[36mINFO\u001b[0m[0058] util.Lookup returned: &{Uid:1000 Gid:1000 Username:iguazio Name: HomeDir:/igz} \n",
      "\u001b[36mINFO\u001b[0m[0058] performing slow lookup of group ids for iguazio \n",
      "\u001b[36mINFO\u001b[0m[0058] Running: [/bin/sh -c pip install \"mlrun[complete]==0.6.0-rc12\"] \n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting mlrun[complete]==0.6.0-rc12\n",
      "  Downloading mlrun-0.6.0rc12-py3-none-any.whl (371 kB)\n",
      "Collecting chardet<4.0,>=3.0.2\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "Collecting sqlalchemy~=1.3\n",
      "  Downloading SQLAlchemy-1.3.23-cp37-cp37m-manylinux2010_x86_64.whl (1.3 MB)\n",
      "Collecting fastapi~=0.62.0\n",
      "  Downloading fastapi-0.62.0-py3-none-any.whl (49 kB)\n",
      "Collecting orjson<3.4,>=3\n",
      "  Downloading orjson-3.3.1-cp37-cp37m-manylinux2014_x86_64.whl (208 kB)\n",
      "Collecting tabulate<=0.8.3,>=0.8.0\n",
      "  Downloading tabulate-0.8.3.tar.gz (46 kB)\n",
      "Collecting dask~=2.12\n",
      "  Downloading dask-2.30.0-py3-none-any.whl (848 kB)\n",
      "Collecting distributed<3,>=2.23\n",
      "  Downloading distributed-2.30.1-py3-none-any.whl (656 kB)\n",
      "Collecting v3io~=0.5.0\n",
      "  Downloading v3io-0.5.7-py3-none-any.whl (49 kB)\n",
      "Collecting kfp~=1.0.1\n",
      "  Downloading kfp-1.0.4.tar.gz (116 kB)\n",
      "Collecting ipython<7.17,>=5.5\n",
      "  Downloading ipython-7.16.1-py3-none-any.whl (785 kB)\n",
      "Collecting humanfriendly~=8.2\n",
      "  Downloading humanfriendly-8.2-py2.py3-none-any.whl (86 kB)\n",
      "Collecting nuclio-jupyter>=0.8.9\n",
      "  Downloading nuclio_jupyter-0.8.9-py3-none-any.whl (47 kB)\n",
      "Collecting click~=7.0\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting pyyaml~=5.1\n",
      "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "Collecting v3io-frames~=0.8.5\n",
      "  Downloading v3io_frames-0.8.14-py3-none-any.whl (35 kB)\n",
      "Collecting semver~=2.13\n",
      "  Downloading semver-2.13.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting pydantic~=1.5\n",
      "  Downloading pydantic-1.7.3-cp37-cp37m-manylinux2014_x86_64.whl (9.1 MB)\n",
      "Collecting alembic~=1.4\n",
      "  Downloading alembic-1.5.4.tar.gz (1.1 MB)\n",
      "Collecting pandas~=1.0\n",
      "  Downloading pandas-1.2.2-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\n",
      "Collecting kubernetes~=11.0\n",
      "  Downloading kubernetes-11.0.0-py3-none-any.whl (1.5 MB)\n",
      "Collecting requests~=2.22\n",
      "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "Collecting urllib3<1.27,>=1.25.4\n",
      "  Downloading urllib3-1.26.3-py2.py3-none-any.whl (137 kB)\n",
      "Collecting mergedeep~=1.3\n",
      "  Downloading mergedeep-1.3.4-py3-none-any.whl (6.4 kB)\n",
      "Collecting aiohttp~=3.6\n",
      "  Downloading aiohttp-3.7.3-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
      "Collecting nest-asyncio~=1.0\n",
      "  Downloading nest_asyncio-1.5.1-py3-none-any.whl (5.0 kB)\n",
      "Collecting GitPython~=3.0\n",
      "  Downloading GitPython-3.1.12-py3-none-any.whl (159 kB)\n",
      "Collecting pyarrow~=1.0\n",
      "  Downloading pyarrow-1.0.1-cp37-cp37m-manylinux2014_x86_64.whl (17.3 MB)\n",
      "Collecting azure-storage-blob~=12.0; extra == \"complete\"\n",
      "  Downloading azure_storage_blob-12.7.1-py2.py3-none-any.whl (339 kB)\n",
      "Collecting boto3~=1.9; extra == \"complete\"\n",
      "  Downloading boto3-1.17.4-py2.py3-none-any.whl (130 kB)\n",
      "Collecting starlette==0.13.6\n",
      "  Downloading starlette-0.13.6-py3-none-any.whl (59 kB)\n",
      "Collecting tornado>=5; python_version < \"3.8\"\n",
      "  Downloading tornado-6.1-cp37-cp37m-manylinux2010_x86_64.whl (428 kB)\n",
      "Collecting tblib>=1.6.0\n",
      "  Downloading tblib-1.7.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting zict>=0.1.3\n",
      "  Downloading zict-2.0.0-py3-none-any.whl (10 kB)\n",
      "Collecting sortedcontainers!=2.0.0,!=2.0.1\n",
      "  Downloading sortedcontainers-2.3.0-py2.py3-none-any.whl (29 kB)\n",
      "Collecting toolz>=0.8.2\n",
      "  Downloading toolz-0.11.1-py3-none-any.whl (55 kB)\n",
      "Collecting cloudpickle>=1.5.0\n",
      "  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/site-packages (from distributed<3,>=2.23->mlrun[complete]==0.6.0-rc12) (45.2.0)\n",
      "Collecting msgpack>=0.6.0\n",
      "  Downloading msgpack-1.0.2-cp37-cp37m-manylinux1_x86_64.whl (273 kB)\n",
      "Collecting psutil>=5.0\n",
      "  Downloading psutil-5.8.0-cp37-cp37m-manylinux2010_x86_64.whl (296 kB)\n",
      "Collecting ujson>=3.0.0\n",
      "  Downloading ujson-4.0.2-cp37-cp37m-manylinux1_x86_64.whl (179 kB)\n",
      "Collecting future>=0.18.2\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "Collecting google-cloud-storage>=1.13.0\n",
      "  Downloading google_cloud_storage-1.35.1-py2.py3-none-any.whl (96 kB)\n",
      "Collecting google-auth>=1.6.1\n",
      "  Downloading google_auth-1.25.0-py2.py3-none-any.whl (116 kB)\n",
      "Collecting requests_toolbelt>=0.8.0\n",
      "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
      "Collecting kfp-server-api<2.0.0,>=0.2.5\n",
      "  Downloading kfp-server-api-1.3.0.tar.gz (54 kB)\n",
      "Collecting jsonschema>=3.0.1\n",
      "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
      "Collecting Deprecated\n",
      "  Downloading Deprecated-1.2.11-py2.py3-none-any.whl (9.1 kB)\n",
      "Collecting strip-hints\n",
      "  Downloading strip-hints-0.1.9.tar.gz (30 kB)\n",
      "Collecting pickleshare\n",
      "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
      "Collecting traitlets>=4.2\n",
      "  Downloading traitlets-5.0.5-py3-none-any.whl (100 kB)\n",
      "Collecting decorator\n",
      "  Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Collecting pygments\n",
      "  Downloading Pygments-2.7.4-py3-none-any.whl (950 kB)\n",
      "Collecting pexpect; sys_platform != \"win32\"\n",
      "  Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
      "Collecting jedi>=0.10\n",
      "  Downloading jedi-0.18.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Collecting backcall\n",
      "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
      "  Downloading prompt_toolkit-3.0.14-py3-none-any.whl (359 kB)\n",
      "Collecting nbconvert>=5.4\n",
      "  Downloading nbconvert-6.0.7-py3-none-any.whl (552 kB)\n",
      "Collecting notebook>=5.2.0\n",
      "  Downloading notebook-6.2.0-py3-none-any.whl (9.5 MB)\n",
      "Collecting googleapis-common-protos>=1.5.3\n",
      "  Downloading googleapis_common_protos-1.52.0-py2.py3-none-any.whl (100 kB)\n",
      "Collecting grpcio-tools==1.30.0\n",
      "  Downloading grpcio_tools-1.30.0-cp37-cp37m-manylinux2010_x86_64.whl (2.5 MB)\n",
      "Collecting grpcio==1.30.0\n",
      "  Downloading grpcio-1.30.0-cp37-cp37m-manylinux2010_x86_64.whl (3.0 MB)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.1.4.tar.gz (479 kB)\n",
      "Collecting python-editor>=0.3\n",
      "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
      "Collecting python-dateutil\n",
      "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Collecting pytz>=2017.3\n",
      "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
      "Collecting numpy>=1.16.5\n",
      "  Downloading numpy-1.20.1-cp37-cp37m-manylinux2010_x86_64.whl (15.3 MB)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0\n",
      "  Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\n",
      "Collecting certifi>=14.05.14\n",
      "  Downloading certifi-2020.12.5-py2.py3-none-any.whl (147 kB)\n",
      "Collecting six>=1.9.0\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting requests-oauthlib\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting idna<3,>=2.5\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Collecting async-timeout<4.0,>=3.0\n",
      "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142 kB)\n",
      "Collecting typing-extensions>=3.6.5\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting attrs>=17.3.0\n",
      "  Downloading attrs-20.3.0-py2.py3-none-any.whl (49 kB)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.5-py3-none-any.whl (63 kB)\n",
      "Collecting cryptography>=2.1.4\n",
      "  Downloading cryptography-3.4.3-cp36-abi3-manylinux2014_x86_64.whl (3.2 MB)\n",
      "Collecting msrest>=0.6.18\n",
      "  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\n",
      "Collecting azure-core<2.0.0,>=1.10.0\n",
      "  Downloading azure_core-1.11.0-py2.py3-none-any.whl (127 kB)\n",
      "Collecting s3transfer<0.4.0,>=0.3.0\n",
      "  Downloading s3transfer-0.3.4-py2.py3-none-any.whl (69 kB)\n",
      "Collecting botocore<1.21.0,>=1.20.4\n",
      "  Downloading botocore-1.20.4-py2.py3-none-any.whl (7.2 MB)\n",
      "Collecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting heapdict\n",
      "  Downloading HeapDict-1.0.1-py3-none-any.whl (3.9 kB)\n",
      "Collecting google-cloud-core<2.0dev,>=1.4.1\n",
      "  Downloading google_cloud_core-1.6.0-py2.py3-none-any.whl (28 kB)\n",
      "Collecting google-resumable-media<2.0dev,>=1.2.0\n",
      "  Downloading google_resumable_media-1.2.0-py2.py3-none-any.whl (75 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Downloading rsa-4.7-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.1-py3-none-any.whl (12 kB)\n",
      "Collecting importlib-metadata; python_version < \"3.8\"\n",
      "  Downloading importlib_metadata-3.4.0-py3-none-any.whl (10 kB)\n",
      "Collecting pyrsistent>=0.14.0\n",
      "  Downloading pyrsistent-0.17.3.tar.gz (106 kB)\n",
      "Collecting wrapt<2,>=1.10\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.7/site-packages (from strip-hints->kfp~=1.0.1->mlrun[complete]==0.6.0-rc12) (0.34.2)\n",
      "Collecting ipython-genutils\n",
      "  Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting ptyprocess>=0.5\n",
      "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting parso<0.9.0,>=0.8.0\n",
      "  Downloading parso-0.8.1-py2.py3-none-any.whl (93 kB)\n",
      "Collecting wcwidth\n",
      "  Downloading wcwidth-0.2.5-py2.py3-none-any.whl (30 kB)\n",
      "Collecting entrypoints>=0.2.2\n",
      "  Downloading entrypoints-0.3-py2.py3-none-any.whl (11 kB)\n",
      "Collecting defusedxml\n",
      "  Downloading defusedxml-0.6.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting jinja2>=2.4\n",
      "  Downloading Jinja2-2.11.3-py2.py3-none-any.whl (125 kB)\n",
      "Collecting jupyter-core\n",
      "  Downloading jupyter_core-4.7.1-py3-none-any.whl (82 kB)\n",
      "Collecting bleach\n",
      "  Downloading bleach-3.3.0-py2.py3-none-any.whl (283 kB)\n",
      "Collecting nbformat>=4.4\n",
      "  Downloading nbformat-5.1.2-py3-none-any.whl (113 kB)\n",
      "Collecting jupyterlab-pygments\n",
      "  Downloading jupyterlab_pygments-0.1.2-py2.py3-none-any.whl (4.6 kB)\n",
      "Collecting nbclient<0.6.0,>=0.5.0\n",
      "  Downloading nbclient-0.5.1-py3-none-any.whl (65 kB)\n",
      "Collecting pandocfilters>=1.4.1\n",
      "  Downloading pandocfilters-1.4.3.tar.gz (16 kB)\n",
      "Collecting testpath\n",
      "  Downloading testpath-0.4.4-py2.py3-none-any.whl (163 kB)\n",
      "Collecting mistune<2,>=0.8.1\n",
      "  Downloading mistune-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting jupyter-client>=5.3.4\n",
      "  Downloading jupyter_client-6.1.11-py3-none-any.whl (108 kB)\n",
      "Collecting Send2Trash>=1.5.0\n",
      "  Downloading Send2Trash-1.5.0-py3-none-any.whl (12 kB)\n",
      "Collecting terminado>=0.8.3\n",
      "  Downloading terminado-0.9.2-py3-none-any.whl (14 kB)\n",
      "Collecting ipykernel\n",
      "  Downloading ipykernel-5.4.3-py3-none-any.whl (120 kB)\n",
      "Collecting prometheus-client\n",
      "  Downloading prometheus_client-0.9.0-py2.py3-none-any.whl (53 kB)\n",
      "Collecting pyzmq>=17\n",
      "  Downloading pyzmq-22.0.2-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
      "Collecting argon2-cffi\n",
      "  Downloading argon2_cffi-20.1.0-cp35-abi3-manylinux1_x86_64.whl (97 kB)\n",
      "Collecting protobuf>=3.6.0\n",
      "  Downloading protobuf-3.14.0-cp37-cp37m-manylinux1_x86_64.whl (1.0 MB)\n",
      "Collecting MarkupSafe>=0.9.2\n",
      "  Downloading MarkupSafe-1.1.1-cp37-cp37m-manylinux2010_x86_64.whl (33 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting smmap<4,>=3.0.1\n",
      "  Downloading smmap-3.0.5-py2.py3-none-any.whl (25 kB)\n",
      "Collecting cffi>=1.12\n",
      "  Downloading cffi-1.14.4-cp37-cp37m-manylinux1_x86_64.whl (402 kB)\n",
      "Collecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
      "Collecting google-api-core<2.0.0dev,>=1.21.0\n",
      "  Downloading google_api_core-1.26.0-py2.py3-none-any.whl (92 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\"\n",
      "  Downloading google_crc32c-1.1.2-cp37-cp37m-manylinux2014_x86_64.whl (38 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.4.0-py3-none-any.whl (5.2 kB)\n",
      "Collecting webencodings\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Collecting packaging\n",
      "  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
      "Collecting async-generator\n",
      "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "Collecting pyparsing>=2.0.2\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Building wheels for collected packages: tabulate, kfp, alembic, future, kfp-server-api, strip-hints, Mako, pyrsistent, wrapt, pandocfilters\n",
      "  Building wheel for tabulate (setup.py): started\n",
      "  Building wheel for tabulate (setup.py): finished with status 'done'\n",
      "  Created wheel for tabulate: filename=tabulate-0.8.3-py3-none-any.whl size=23378 sha256=1878be3a7015fbdce18e24a76edf5f682fd59da4dfe2b608e41212126013e5bf\n",
      "  Stored in directory: /igz/.cache/pip/wheels/b8/a2/a6/812a8a9735b090913e109133c7c20aaca4cf07e8e18837714f\n",
      "  Building wheel for kfp (setup.py): started\n",
      "  Building wheel for kfp (setup.py): finished with status 'done'\n",
      "  Created wheel for kfp: filename=kfp-1.0.4-py3-none-any.whl size=159872 sha256=92e3040007e63555bf32d3e172739da8c00dafe33d9d1d05756592038028a7fb\n",
      "  Stored in directory: /igz/.cache/pip/wheels/65/1c/be/3d7366d2288bf1587e4fe6cd0c1ebdce5e3bada21b70a29e66\n",
      "  Building wheel for alembic (setup.py): started\n",
      "  Building wheel for alembic (setup.py): finished with status 'done'\n",
      "  Created wheel for alembic: filename=alembic-1.5.4-py2.py3-none-any.whl size=156316 sha256=67c8e4104eb8008d708754110fc4e0af57a0f05471190674cdb306ca4abc3d28\n",
      "  Stored in directory: /igz/.cache/pip/wheels/f2/80/ed/cab9b0d74b8a82204a4d70477c4a8a3c6431c5f1dc762c1a28\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491058 sha256=78f5a08c06d88aba01663d0f92d4bd94e12cac2cf4001beb48445cbb6323bc52\n",
      "  Stored in directory: /igz/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
      "  Building wheel for kfp-server-api (setup.py): started\n",
      "  Building wheel for kfp-server-api (setup.py): finished with status 'done'\n",
      "  Created wheel for kfp-server-api: filename=kfp_server_api-1.3.0-py3-none-any.whl size=108019 sha256=464cf11044d9ca7a2eb4a65e81ad11a142274694b4a757e0047230dae7d427ed\n",
      "  Stored in directory: /igz/.cache/pip/wheels/40/c1/57/7c3f9134d56eda563ad945a904e9e2edbd22479b292558659e\n",
      "  Building wheel for strip-hints (setup.py): started\n",
      "  Building wheel for strip-hints (setup.py): finished with status 'done'\n",
      "  Created wheel for strip-hints: filename=strip_hints-0.1.9-py2.py3-none-any.whl size=20993 sha256=a4e513bafdfacbf1a9f75356024240918ce061e55060967f87d6240a55e8db2c\n",
      "  Stored in directory: /igz/.cache/pip/wheels/2d/b8/4e/a3ec111d2db63cec88121bd7c0ab1a123bce3b55dd19dda5c1\n",
      "  Building wheel for Mako (setup.py): started\n",
      "  Building wheel for Mako (setup.py): finished with status 'done'\n",
      "  Created wheel for Mako: filename=Mako-1.1.4-py2.py3-none-any.whl size=75675 sha256=465cd3e307859caac6dea3d433bdbe2c4c8a1970af629691d6dc8fcc790eb8c2\n",
      "  Stored in directory: /igz/.cache/pip/wheels/2a/60/32/02a16820f96c067f6161ef35c21559f8db52c4158d6602b438\n",
      "  Building wheel for pyrsistent (setup.py): started\n",
      "  Building wheel for pyrsistent (setup.py): finished with status 'done'\n",
      "  Created wheel for pyrsistent: filename=pyrsistent-0.17.3-cp37-cp37m-linux_x86_64.whl size=55874 sha256=7be192cb5577c0d113228f381c8cf33952d6188328bd6e1822df53c0060448c4\n",
      "  Stored in directory: /igz/.cache/pip/wheels/a5/52/bf/71258a1d7b3c8cbe1ee53f9314c6f65f20385481eaee573cc5\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-py3-none-any.whl size=19553 sha256=d10965b9949c21f00ec50546d38a2c0224d8073020b0c7abe7053eca6dd22649\n",
      "  Stored in directory: /igz/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
      "  Building wheel for pandocfilters (setup.py): started\n",
      "  Building wheel for pandocfilters (setup.py): finished with status 'done'\n",
      "  Created wheel for pandocfilters: filename=pandocfilters-1.4.3-py3-none-any.whl size=7991 sha256=0a0b95926960c54ea107fdc97f9b6045a287df498dc0dce8a95ae7cc03d7937d\n",
      "  Stored in directory: /igz/.cache/pip/wheels/42/81/34/545dc2fbf0e9137811e901108d37fc04650e81d48f97078000\n",
      "Successfully built tabulate kfp alembic future kfp-server-api strip-hints Mako pyrsistent wrapt pandocfilters\n",
      "Installing collected packages: chardet, sqlalchemy, starlette, pydantic, fastapi, orjson, tabulate, pyyaml, dask, tornado, click, tblib, heapdict, zict, sortedcontainers, toolz, cloudpickle, msgpack, psutil, distributed, ujson, future, urllib3, certifi, idna, requests, v3io, pyasn1, pyasn1-modules, six, rsa, cachetools, google-auth, protobuf, googleapis-common-protos, pyparsing, packaging, pytz, google-api-core, google-cloud-core, pycparser, cffi, google-crc32c, google-resumable-media, google-cloud-storage, websocket-client, python-dateutil, oauthlib, requests-oauthlib, kubernetes, requests-toolbelt, kfp-server-api, attrs, typing-extensions, zipp, importlib-metadata, pyrsistent, jsonschema, wrapt, Deprecated, strip-hints, kfp, pickleshare, ipython-genutils, traitlets, decorator, pygments, ptyprocess, pexpect, parso, jedi, backcall, wcwidth, prompt-toolkit, ipython, humanfriendly, jmespath, botocore, s3transfer, boto3, entrypoints, defusedxml, MarkupSafe, jinja2, jupyter-core, webencodings, bleach, nbformat, jupyterlab-pygments, pyzmq, jupyter-client, async-generator, nest-asyncio, nbclient, pandocfilters, testpath, mistune, nbconvert, Send2Trash, terminado, ipykernel, prometheus-client, argon2-cffi, notebook, nuclio-jupyter, grpcio, grpcio-tools, numpy, pandas, v3io-frames, semver, Mako, python-editor, alembic, mergedeep, async-timeout, multidict, yarl, aiohttp, smmap, gitdb, GitPython, pyarrow, cryptography, isodate, msrest, azure-core, azure-storage-blob, mlrun\n",
      "  WARNING: The script chardetect is installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tabulate is installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts dask-scheduler, dask-ssh and dask-worker are installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts futurize and pasteurize are installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts pyrsa-decrypt, pyrsa-encrypt, pyrsa-keygen, pyrsa-priv2pub, pyrsa-sign and pyrsa-verify are installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script jsonschema is installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script strip-hints is installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts dsl-compile and kfp are installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script pygmentize is installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts iptest, iptest3, ipython and ipython3 are installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script humanfriendly is installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts jupyter, jupyter-migrate and jupyter-troubleshoot are installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script jupyter-trust is installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts jupyter-kernel, jupyter-kernelspec and jupyter-run are installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script jupyter-nbconvert is installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts jupyter-bundlerextension, jupyter-nbextension, jupyter-notebook and jupyter-serverextension are installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script nuclio is installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts f2py, f2py3 and f2py3.7 are installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script pysemver is installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script mako-render is installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script alembic is installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script plasma_store is installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script mlrun is installed in '/igz/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "Successfully installed Deprecated-1.2.11 GitPython-3.1.12 Mako-1.1.4 MarkupSafe-1.1.1 Send2Trash-1.5.0 aiohttp-3.7.3 alembic-1.5.4 argon2-cffi-20.1.0 async-generator-1.10 async-timeout-3.0.1 attrs-20.3.0 azure-core-1.11.0 azure-storage-blob-12.7.1 backcall-0.2.0 bleach-3.3.0 boto3-1.17.4 botocore-1.20.4 cachetools-4.2.1 certifi-2020.12.5 cffi-1.14.4 chardet-3.0.4 click-7.1.2 cloudpickle-1.6.0 cryptography-3.4.3 dask-2.30.0 decorator-4.4.2 defusedxml-0.6.0 distributed-2.30.1 entrypoints-0.3 fastapi-0.62.0 future-0.18.2 gitdb-4.0.5 google-api-core-1.26.0 google-auth-1.25.0 google-cloud-core-1.6.0 google-cloud-storage-1.35.1 google-crc32c-1.1.2 google-resumable-media-1.2.0 googleapis-common-protos-1.52.0 grpcio-1.30.0 grpcio-tools-1.30.0 heapdict-1.0.1 humanfriendly-8.2 idna-2.10 importlib-metadata-3.4.0 ipykernel-5.4.3 ipython-7.16.1 ipython-genutils-0.2.0 isodate-0.6.0 jedi-0.18.0 jinja2-2.11.3 jmespath-0.10.0 jsonschema-3.2.0 jupyter-client-6.1.11 jupyter-core-4.7.1 jupyterlab-pygments-0.1.2 kfp-1.0.4 kfp-server-api-1.3.0 kubernetes-11.0.0 mergedeep-1.3.4 mistune-0.8.4 mlrun-0.6.0rc12 msgpack-1.0.2 msrest-0.6.21 multidict-5.1.0 nbclient-0.5.1 nbconvert-6.0.7 nbformat-5.1.2 nest-asyncio-1.5.1 notebook-6.2.0 nuclio-jupyter-0.8.9 numpy-1.20.1 oauthlib-3.1.0 orjson-3.3.1 packaging-20.9 pandas-1.2.2 pandocfilters-1.4.3 parso-0.8.1 pexpect-4.8.0 pickleshare-0.7.5 prometheus-client-0.9.0 prompt-toolkit-3.0.14 protobuf-3.14.0 psutil-5.8.0 ptyprocess-0.7.0 pyarrow-1.0.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycparser-2.20 pydantic-1.7.3 pygments-2.7.4 pyparsing-2.4.7 pyrsistent-0.17.3 python-dateutil-2.8.1 python-editor-1.0.4 pytz-2021.1 pyyaml-5.4.1 pyzmq-22.0.2 requests-2.25.1 requests-oauthlib-1.3.0 requests-toolbelt-0.9.1 rsa-4.7 s3transfer-0.3.4 semver-2.13.0 six-1.15.0 smmap-3.0.5 sortedcontainers-2.3.0 sqlalchemy-1.3.23 starlette-0.13.6 strip-hints-0.1.9 tabulate-0.8.3 tblib-1.7.0 terminado-0.9.2 testpath-0.4.4 toolz-0.11.1 tornado-6.1 traitlets-5.0.5 typing-extensions-3.7.4.3 ujson-4.0.2 urllib3-1.26.3 v3io-0.5.7 v3io-frames-0.8.14 wcwidth-0.2.5 webencodings-0.5.1 websocket-client-0.57.0 wrapt-1.12.1 yarl-1.6.3 zict-2.0.0 zipp-3.4.0\n",
      "WARNING: You are using pip version 20.2.4; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\n",
      "\u001b[36mINFO\u001b[0m[0098] Taking snapshot of full filesystem...        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlrun import new_function\n",
    "#should be converted to an image (spark operator)\n",
    "spark_job = new_function(kind='spark', command='/User/parquez/functions/kv_to_parquet.py', name='kv-to-parquet') # /User isn't supported at this stage\n",
    "project.set_function(spark_job)\n",
    "project.func('kv-to-parquet').with_driver_limits(cpu=\"4000\")\n",
    "project.func('kv-to-parquet').with_driver_requests(cpu=2, mem=\"512m\") # gpu_type & gpus=<number_of_gpus> are supported too\n",
    "project.func('kv-to-parquet').with_executor_limits(cpu=\"4000\")\n",
    "project.func('kv-to-parquet').with_executor_requests(cpu=2, mem=\"512m\")\n",
    "project.func('kv-to-parquet').with_igz_spark() # Adds fuse, daemon & iguazio's jars support\n",
    "project.func('kv-to-parquet').deploy()# Rebuilds the image with MLRun - This is needed in order to support artifact logging etc. This step is too long (~3 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlrun import mount_v3io\n",
    "\n",
    "# create-kv-view\n",
    "project.set_function(\"functions/create_kv_view.py\", 'create-kv-view', kind='job', image=image_name)\n",
    "project.func('create-kv-view').apply(mount_v3io())\n",
    "project.func('create-kv-view').set_env('PYTHONPATH', project_path)\n",
    "project.func('create-kv-view').deploy(with_mlrun=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parquet-add-partition\n",
    "project.set_function(\"functions/parquet_add_partition.py\", 'parquet-add-partition', kind='job', image=image_name)\n",
    "project.func('parquet-add-partition').apply(mount_v3io())\n",
    "project.func('parquet-add-partition').set_env('PYTHONPATH', project_path)\n",
    "project.func('parquet-add-partition').deploy(with_mlrun=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#delete-kv-partition\n",
    "project.set_function(\"functions/delete_kv_partition.py\", 'delete-kv-partition', kind='job', image=image_name)\n",
    "project.func('delete-kv-partition').apply(mount_v3io())\n",
    "project.func('delete-kv-partition').set_env('PYTHONPATH', project_path)\n",
    "project.func('delete-kv-partition').deploy(with_mlrun=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parquetinizer\n",
    "project.set_function(\"functions/parquetinizer.py\", 'parquetinizer', kind='job', image=image_name)\n",
    "project.func('parquetinizer').apply(mount_v3io())\n",
    "project.func('parquetinizer').set_env('PYTHONPATH', project_path)\n",
    "project.func('parquetinizer').deploy(with_mlrun=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-step-create-n-run-ml-pipeline\"></a>\n",
    "## Create and Run a Fully Automated ML Pipeline\n",
    "\n",
    "You're now ready to create a full ML pipeline.\n",
    "This is done by using [Kubeflow Pipelines](https://www.kubeflow.org/docs/pipelines/overview/pipelines-overview/), which is integrated into the Iguazio Data Science Platform.\n",
    "Kubeflow Pipelines is an open-source framework for building and deploying portable, scalable machine-learning workflows based on Docker containers.\n",
    "MLRun leverages this framework to take your existing code and deploy it as steps in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /User/parquez/workflow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {path.join(project_path, 'workflow.py')}\n",
    "\n",
    "from kfp import dsl\n",
    "from mlrun import mount_v3io\n",
    "from os import path\n",
    "import os\n",
    "\n",
    "V3IO_ACCESS_KEY = os.environ['V3IO_ACCESS_KEY']\n",
    "V3IO_USERNAME = os.getenv('V3IO_USERNAME')\n",
    "\n",
    "funcs = {}\n",
    "project_path = path.abspath('./')\n",
    "parquez_params = {'view_name':'view_name'\n",
    "         ,'partition_by':'h'\n",
    "         ,'partition_interval':'1h'\n",
    "         ,'real_time_window':'3h'\n",
    "         ,'historical_retention':'24h'\n",
    "         ,'real_time_table_name':'faker'\n",
    "         ,'config_path':'/User/parquez/config/parquez.ini'\n",
    "         ,'user_name':V3IO_USERNAME\n",
    "         ,'access_key':V3IO_ACCESS_KEY          \n",
    "         ,'project_path': project_path\n",
    "         }\n",
    "\n",
    "\n",
    "# Configure function resources and local settings\n",
    "def init_functions(functions: dict, project=None, secrets=None):\n",
    "    project_path = path.abspath('./')\n",
    "    for f in functions.values():\n",
    "        f.apply(mount_v3io())\n",
    "        f.set_env('PYTHONPATH', project_path)\n",
    "        f.spec.artifact_path = 'User/artifacts'\n",
    "        f.spec.service_account='mlrun-api'\n",
    "        \n",
    "        \n",
    "# Create a Kubeflow Pipelines pipeline\n",
    "@dsl.pipeline(\n",
    "    name = \"parquez-pipeline\",\n",
    "    description = \"parquez description\"\n",
    ")\n",
    "def kfpipeline():\n",
    "    \n",
    "#     # clean the tables\n",
    "#     clean = funcs['clean'].as_step(\n",
    "#         name=\"clean\",\n",
    "#         params=parquez_params,\n",
    "#         outputs=['clean']\n",
    "#     )\n",
    "    \n",
    "    # Ingest the data set\n",
    "    validate = funcs['validate'].as_step(\n",
    "        name=\"validate\",\n",
    "        params=parquez_params,\n",
    "#         inputs={'table': clean.outputs},\n",
    "        outputs=['validate']\n",
    "    )\n",
    "    \n",
    "    # Analyze the dataset\n",
    "    schema = funcs['get_schema'].as_step(\n",
    "        name=\"get_schema\",\n",
    "        params = parquez_params,\n",
    "        inputs={'table': validate.outputs},                       \n",
    "        outputs=['schema']\n",
    "    )\n",
    "    \n",
    "    parquet = funcs[\"create_parquet\"].as_step(\n",
    "        name=\"create_parquet\",\n",
    "        params=parquez_params,\n",
    "        inputs={\"table\": schema.outputs['schema']},\n",
    "        outputs=['create_parquet']\n",
    "    )\n",
    "    \n",
    "    kv_view = funcs[\"create-kv-view\"].as_step(\n",
    "        name=\"create_kv_view\",\n",
    "        params=parquez_params,\n",
    "        inputs={'table': parquet.outputs},\n",
    "        outputs=['kv_view']\n",
    "    )\n",
    "    \n",
    "    unified_view = funcs[\"create_unified_view\"].as_step(\n",
    "        name=\"create_unified_view\",\n",
    "        params=parquez_params,\n",
    "        inputs={'table': kv_view.outputs},\n",
    "        outputs=['unified_view']\n",
    "    )\n",
    "    \n",
    "    unified_view = funcs[\"run_scheduler\"].as_step(\n",
    "        name=\"run_scheduler\",\n",
    "        params=parquez_params,\n",
    "        inputs={'table': unified_view.outputs},\n",
    "        outputs=['run_scheduler']\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-register-workflow\"></a>\n",
    "#### Register the Workflow\n",
    "\n",
    "Use the `set_workflow` MLRun project method to register your workflow with MLRun.\n",
    "The following code sets the `name` parameter to the selected workflow name (\"main\") and the `code` parameter to the name of the workflow file that is found in your project directory (**workflow.py**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the workflow file as \"main\"\n",
    "project.set_workflow('main', 'workflow.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-02-09 13:48:20,868 [info] using in-cluster config.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"https://dashboard.default-tenant.app.app-lab-eks-b5963-2.iguazio-cd1.com/pipelines/#/experiments/details/0fcf7e3c-ec8b-460c-b691-18e6a5904d07\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"https://dashboard.default-tenant.app.app-lab-eks-b5963-2.iguazio-cd1.com/pipelines/#/runs/details/d0515eb3-dbdd-4bfd-a586-c01a19aac528\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-02-09 13:48:21,431 [info] Pipeline run id=d0515eb3-dbdd-4bfd-a586-c01a19aac528, check UI or DB for progress\n"
     ]
    }
   ],
   "source": [
    "run_id = project.run(\n",
    "    'main',\n",
    "    arguments={}, \n",
    "    \n",
    "    artifact_path=path.abspath(path.join('pipeline','{{workflow.uid}}'),\n",
    "    \n",
    "                              )\n",
    "    ,dirty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SchedulesOutput(schedules=[])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlrun import get_run_db\n",
    "get_run_db().list_schedules('parquez')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
